{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8112d098",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import pandas as pd \n",
    "import os \n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a164e533",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyts.classification import BOSSVS\n",
    "from pyts.multivariate.classification import MultivariateClassifier\n",
    "import shutil\n",
    "from keras.callbacks import CSVLogger\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import dstack\n",
    "from pandas import read_csv\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import ShuffleSplit # or StratifiedShuffleSplit\n",
    "from pandas import DataFrame\n",
    "import sktime\n",
    "from sktime.classification.distance_based import KNeighborsTimeSeriesClassifier\n",
    "from datetime import datetime\n",
    "from keras.layers import Conv1D, Dense, Dropout, Input, Concatenate, GlobalMaxPooling1D, BatchNormalization\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import dstack\n",
    "\n",
    "from matplotlib import pyplot\n",
    "import tensorflow.keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten,LSTM\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense, Activation, Concatenate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import ShuffleSplit # or StratifiedShuffleSplit\n",
    "from pandas import DataFrame\n",
    "import os\n",
    "import IPython\n",
    "from IPython.display import Audio\n",
    "import scipy\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.tree import export_graphviz\n",
    "# import mglearn\n",
    "import graphviz\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "from PIL import Image\n",
    "from keras.layers import Conv1D\n",
    "from sklearn.metrics import f1_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten,LSTM\n",
    "from keras.utils import to_categorical\n",
    "from datetime import datetime\n",
    "from keras.layers import Conv1D, Dense, Dropout, Input, Concatenate, GlobalMaxPooling1D, BatchNormalization,GlobalAveragePooling1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "\n",
    "import tensorflow \n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "# Importing the cv2 module\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db23d484",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b59d31e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import dirname, join as pjoin\n",
    "from scipy.io import wavfile\n",
    "import scipy.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee3c9d32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fname=\"C:/Users/pierr/Documents_kanop/Shps/Pierre_points_for_louis/Bureau/LABALA.csv\"\n",
    "\n",
    "os.path.isfile(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c8e30a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_data=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1436a458",
   "metadata": {},
   "outputs": [],
   "source": [
    "#VERSION TEST DONNEES NON LABELLISEES\n",
    "\n",
    "data_dir=\"C:/Users/pierr/Documents_kanop/Shps/Pierre_points_for_louis/Bureau/data_emotions/audio_speech_actors/\"\n",
    "\n",
    "\n",
    "\n",
    "data_files=[]\n",
    "file_names=[]\n",
    "\n",
    "\n",
    "# Class=np.array(labels[\"Class\"])\n",
    "# fnames=np.array(labels[\"Filename\"])\n",
    "\n",
    "\n",
    "\n",
    "for filename in os.listdir(data_dir):\n",
    "    f = os.path.join(data_dir,filename)\n",
    "    data_files.append(f)\n",
    "    file_names.append(filename)\n",
    "    meta_data.append([f,filename])\n",
    "        \n",
    "\n",
    "data=pd.DataFrame(data_files,file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e03ca38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "\n",
    "def condition(x):\n",
    "    if x.startswith('03-01-03'):\n",
    "        return 'Happy'\n",
    "    elif x.startswith('03-01-04'):\n",
    "        return 'Sad'\n",
    "    elif x.startswith('03-01-05'):\n",
    "        return 'Angry'\n",
    "    elif x.startswith('03-01-06'):\n",
    "        return 'Fearful'\n",
    "    elif x.startswith('03-01-07'):\n",
    "        return 'Disgust'\n",
    "    else :\n",
    "        return 'Surprised'\n",
    " \n",
    "\n",
    "meta_data = []\n",
    "for dirname, _, filenames in os.walk(\"C:/Users/pierr/Documents_kanop/Shps/Pierre_points_for_louis/Bureau/data_emotions/audio_speech_actors/\"):\n",
    "    for filename in filenames:\n",
    "        meta_data.append([filename, os.path.join(dirname,filename)])\n",
    "        \n",
    "        \n",
    "data = pd.DataFrame(meta_data, columns=['fichier','source'])\n",
    "\n",
    "data['actor'] = data['source'].apply(lambda x : re.findall(\"\\w+_\\d+\",x)[0])\n",
    "\n",
    "data = data[data['actor']!=\"audio_speech_actors_01\"]\n",
    "data.reset_index(inplace=True,drop=True)\n",
    "\n",
    "data['Classe'] = data['fichier'].apply(lambda x: re.split(\"-\\d+\\.wav\",x)[0])\n",
    "\n",
    "data['Sexe'] = data['actor'].apply(lambda x : 'Femelle' if int(x.split('_')[1])%2==0 else 'MÃ¢le')\n",
    "\n",
    "data['Labels'] = data['Classe'].apply(condition)\n",
    "\n",
    "#Choice of two categories to compare\n",
    "\n",
    "# dataH=data[data['Labels']=='Happy'].copy()   \n",
    "# dataS=data[data['Labels']=='Sad'].copy()\n",
    "# data=pd.concat([dataH,dataS])\n",
    "\n",
    "# dataF=data[data['Labels']=='Fearful'].copy()   \n",
    "# dataD=data[data['Labels']=='Disgust'].copy()\n",
    "# data=pd.concat([dataF,dataD])\n",
    "\n",
    "dataSUR=data[data['Labels']=='Surprised'].copy()   \n",
    "dataANG=data[data['Labels']=='Anger'].copy()\n",
    "data=pd.concat([dataSUR,dataANG])\n",
    "data.reset_index()\n",
    "\n",
    "fnames=np.array(data['fichier'])\n",
    "actors=np.array(data['actor'])\n",
    "\n",
    "                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "800f921f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "Length= []\n",
    "\n",
    "for i in range(len(fnames)):\n",
    "    \n",
    "    wav_fname = pjoin(data_dir,actors[i], fnames[i])\n",
    "    samplerate, data_sample = wavfile.read(wav_fname)\n",
    "    number_of_channels = 1\n",
    "    length = data_sample.shape[0] / samplerate\n",
    "\n",
    "    Data=np.array(data_sample).astype(float)\n",
    "    \n",
    "    lg = len(librosa.feature.spectral_bandwidth(y=Data)[0])\n",
    "    Length.append(lg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72be3d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling=False\n",
    "\n",
    "def scaler(array):\n",
    "    scaler = MinMaxScaler()\n",
    "    array=array.reshape(-1,1)\n",
    "    scaler.fit(array)\n",
    "    array=scaler.transform(array)\n",
    "    return array\n",
    "\n",
    "sample_length= []\n",
    "\n",
    "\n",
    "MFCC_H=np.zeros((len(fnames),min(Length)))\n",
    "\n",
    "spectral_bandwidth=np.zeros((len(fnames),min(Length)))\n",
    "rms=np.zeros((len(fnames),min(Length)))\n",
    "CONTRAST=np.zeros((len(fnames),min(Length)))\n",
    "\n",
    "\n",
    "Lim = min(Length)\n",
    "\n",
    "for i in range(len(fnames)):\n",
    "    \n",
    "    \n",
    "    \n",
    "    wav_fname = pjoin(data_dir,actors[i], fnames[i])\n",
    "    samplerate, data_sample = wavfile.read(wav_fname)\n",
    "    number_of_channels = 1\n",
    "    length = data_sample.shape[0] / samplerate\n",
    "    sample_length.append(length)\n",
    "  \n",
    "    Data=np.array(data_sample).astype(float)\n",
    "\n",
    "    lib_STFT=np.abs(librosa.stft(Data)) \n",
    "    contrast=np.mean(librosa.feature.spectral_contrast(S=lib_STFT),axis=0)\n",
    "\n",
    "    if scaling==True: \n",
    "        \n",
    "        RMS= scaler(librosa.feature.rms(y=Data))\n",
    "        SPC_BW= scaler(librosa.feature.spectral_bandwidth(y=Data)[0])\n",
    "        mfcc_h = scaler(np.mean(librosa.feature.mfcc(y=Data),axis = 0))\n",
    "        contrast=scaler(np.mean(librosa.feature.spectral_contrast(S=lib_STFT),axis=0))\n",
    "        \n",
    "    if scaling==False:\n",
    "        \n",
    "        RMS= librosa.feature.rms(y=Data)[0]\n",
    "        SPC_BW= librosa.feature.spectral_bandwidth(y=Data)[0]\n",
    "        mfcc_h = np.mean(librosa.feature.mfcc(y=Data),axis = 0)\n",
    "        contrast=np.mean(librosa.feature.spectral_contrast(S=lib_STFT),axis=0)\n",
    "\n",
    "    if len(mfcc_h)>min(Length):\n",
    "        spectral_bandwidth[i]=SPC_BW[:Lim].flatten()\n",
    "        MFCC_H[i]=mfcc_h[:Lim].flatten()\n",
    "\n",
    "        \n",
    "        rms[i]=RMS[:Lim].flatten()\n",
    "        CONTRAST[i]=contrast[:Lim].flatten()\n",
    "    else:\n",
    "        \n",
    "        spectral_bandwidth[i]=SPC_BW.flatten()\n",
    "        MFCC_H[i]=mfcc_h.flatten()\n",
    "        CONTRAST[i]=contrast.flatten()\n",
    "        rms[i]=RMS.flatten()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09be79d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(477, 276)\n",
      "(477, 276)\n",
      "(477, 276)\n",
      "(477, 276)\n"
     ]
    }
   ],
   "source": [
    "print(MFCC_H.shape)\n",
    "print(rms.shape)\n",
    "print(spectral_bandwidth.shape)\n",
    "print(CONTRAST.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4b9b4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_matrix=np.zeros((4,len(fnames),min(Length)))\n",
    "\n",
    "data_matrix[0]=MFCC_H\n",
    "data_matrix[1]=rms\n",
    "data_matrix[2]=spectral_bandwidth\n",
    "data_matrix[3]=CONTRAST\n",
    "\n",
    "data_matrix=np.reshape(data_matrix,(len(fnames),Lim,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "294efcec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "6/6 [==============================] - 1s 54ms/step - loss: 0.6169 - val_loss: 0.0042\n",
      "Epoch 2/50\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.0016 - val_loss: 5.2355e-04\n",
      "Epoch 3/50\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 1.8719e-04 - val_loss: 2.4394e-05\n",
      "Epoch 4/50\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 4.0335e-06 - val_loss: 4.5937e-07\n",
      "Epoch 5/50\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 5.1220e-08 - val_loss: 4.1962e-08\n",
      "Epoch 6/50\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 4.9830e-09 - val_loss: 1.0486e-08\n",
      "Epoch 7/50\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 2.0656e-09 - val_loss: 4.7220e-09\n",
      "Epoch 8/50\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 8.2208e-10 - val_loss: 2.9961e-09\n",
      "Epoch 9/50\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 6.0238e-10 - val_loss: 2.3157e-09\n",
      "Epoch 10/50\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 4.7883e-10 - val_loss: 2.0030e-09\n",
      "Epoch 11/50\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 4.1975e-10 - val_loss: 1.8466e-09\n",
      "Epoch 12/50\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 3.8929e-10 - val_loss: 1.7646e-09\n",
      "Epoch 13/50\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 3.7182e-10 - val_loss: 1.7205e-09\n",
      "Epoch 14/50\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 3.6497e-10 - val_loss: 1.6962e-09\n",
      "Epoch 15/50\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 3.6028e-10 - val_loss: 1.6826e-09\n",
      "Epoch 16/50\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 3.5819e-10 - val_loss: 1.6749e-09\n",
      "Epoch 17/50\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 3.5673e-10 - val_loss: 1.6703e-09\n",
      "Epoch 18/50\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 3.5584e-10 - val_loss: 1.6675e-09\n",
      "Epoch 19/50\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 3.5517e-10 - val_loss: 1.6656e-09\n",
      "Epoch 20/50\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 3.5487e-10 - val_loss: 1.6641e-09\n",
      "Epoch 21/50\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 3.5451e-10 - val_loss: 1.6631e-09\n",
      "Epoch 22/50\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 3.5431e-10 - val_loss: 1.6620e-09\n",
      "Epoch 23/50\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 3.5409e-10 - val_loss: 1.6610e-09\n",
      "Epoch 24/50\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 3.5384e-10 - val_loss: 1.6602e-09\n",
      "Epoch 25/50\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 3.5361e-10 - val_loss: 1.6594e-09\n",
      "Epoch 26/50\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 3.5346e-10 - val_loss: 1.6584e-09\n",
      "Epoch 27/50\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 3.5326e-10 - val_loss: 1.6575e-09\n",
      "Epoch 28/50\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 3.5302e-10 - val_loss: 1.6566e-09\n",
      "Epoch 29/50\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 3.5279e-10 - val_loss: 1.6558e-09\n",
      "Epoch 30/50\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 3.5263e-10 - val_loss: 1.6548e-09\n",
      "Epoch 31/50\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 3.5237e-10 - val_loss: 1.6539e-09\n",
      "Epoch 32/50\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 3.5217e-10 - val_loss: 1.6529e-09\n",
      "Epoch 33/50\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 3.5194e-10 - val_loss: 1.6519e-09\n",
      "Epoch 34/50\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 3.5166e-10 - val_loss: 1.6510e-09\n",
      "Epoch 35/50\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 3.5146e-10 - val_loss: 1.6498e-09\n",
      "Epoch 36/50\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 3.5122e-10 - val_loss: 1.6487e-09\n",
      "Epoch 37/50\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 3.5095e-10 - val_loss: 1.6475e-09\n",
      "Epoch 38/50\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 3.5064e-10 - val_loss: 1.6465e-09\n",
      "Epoch 39/50\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 3.5040e-10 - val_loss: 1.6454e-09\n",
      "Epoch 40/50\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 3.5013e-10 - val_loss: 1.6442e-09\n",
      "Epoch 41/50\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 3.4991e-10 - val_loss: 1.6430e-09\n",
      "Epoch 42/50\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 3.4963e-10 - val_loss: 1.6418e-09\n",
      "Epoch 43/50\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 3.4929e-10 - val_loss: 1.6407e-09\n",
      "Epoch 44/50\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 3.4905e-10 - val_loss: 1.6395e-09\n",
      "Epoch 45/50\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 3.4884e-10 - val_loss: 1.6381e-09\n",
      "Epoch 46/50\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 3.4847e-10 - val_loss: 1.6370e-09\n",
      "Epoch 47/50\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 3.4821e-10 - val_loss: 1.6358e-09\n",
      "Epoch 48/50\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 3.4797e-10 - val_loss: 1.6346e-09\n",
      "Epoch 49/50\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 3.4765e-10 - val_loss: 1.6336e-09\n",
      "Epoch 50/50\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 3.4743e-10 - val_loss: 1.6324e-09\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f701c64070>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#MAIN ANALYSIS 6 EMOTIONS\n",
    "\n",
    "Labels=data['Labels'].reset_index()\n",
    "\n",
    "Num_labels= []\n",
    "\n",
    "for i in range(len(fnames)):\n",
    "#     if Labels[\"Labels\"][i]=='Happy':\n",
    "#         Num_labels.append(0)\n",
    "#     if Labels[\"Labels\"][i]=='Sad':\n",
    "#         Num_labels.append(1)\n",
    "    \n",
    "#     if Labels[\"Labels\"][i]=='Fearful':\n",
    "#         Num_labels.append(0)\n",
    "#     if Labels[\"Labels\"][i]=='Disgust':\n",
    "#         Num_labels.append(1)\n",
    "    if Labels[\"Labels\"][i]=='Angry':\n",
    "        Num_labels.append(0)\n",
    "    if Labels[\"Labels\"][i]=='Surprised':\n",
    "        Num_labels.append(1)        \n",
    "        \n",
    "#     if Labels[i]=='Angry':\n",
    "#         Num_labels.append(2)\n",
    "#     if Labels[i]=='Fearful':\n",
    "#         Num_labels.append(3)\n",
    "#     if Labels[i]=='Disgust':\n",
    "#         Num_labels.append(4)\n",
    "#     if Labels[i]=='Surprised':\n",
    "#         Num_labels.append(5)\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential([\n",
    "\n",
    "  layers.Conv1D(126, 1, padding='same', activation='relu', input_shape=(Lim,1)),\n",
    "  layers.MaxPooling1D(),\n",
    "  layers.Conv1D(64, 1, padding='same', activation='relu'),\n",
    "  layers.MaxPooling1D(),\n",
    "\n",
    "  layers.Conv1D(32, 1, padding='same', activation='relu'),\n",
    "  layers.MaxPooling1D(),\n",
    "\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(16, activation='relu'),\n",
    "    \n",
    "  layers.Dense(2,activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam',loss='binary_crossentropy' )\n",
    "\n",
    "# FULL EMOTIONS  TRAINING\n",
    "    \n",
    "x_train, x_test, y_train, y_test = train_test_split(MFCC_H, Num_labels, test_size=0.05, random_state=np.random.randint(500))\n",
    "# x_train = x_train.to_numpy()int()\n",
    "y_train = to_categorical(y_train)\n",
    "# y_train = to_categorical(y_train)\n",
    "# y_test = to_categorical(y_test)\n",
    "\n",
    "#fitting data\n",
    "model.fit(x_train, y_train,epochs=50,batch_size=64,validation_split=0.2)\n",
    "\n",
    "#Obtain the accuracy of prediction for each class\n",
    "# print(np.round(model.predict(x_test),1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f6770d15",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3/3 [==============================] - 6s 636ms/step - loss: 3.0953 - accuracy: 0.4503 - val_loss: 2.9491 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 1s 187ms/step - loss: 2.9771 - accuracy: 0.4448 - val_loss: 2.8858 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 1s 186ms/step - loss: 2.8741 - accuracy: 0.4475 - val_loss: 2.8243 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 1s 178ms/step - loss: 2.7899 - accuracy: 0.4530 - val_loss: 2.7635 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 1s 189ms/step - loss: 2.7221 - accuracy: 0.4834 - val_loss: 2.7033 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 1s 178ms/step - loss: 2.6611 - accuracy: 0.5414 - val_loss: 2.6442 - val_accuracy: 0.0110\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 1s 186ms/step - loss: 2.6020 - accuracy: 0.5635 - val_loss: 2.5863 - val_accuracy: 0.0440\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 1s 186ms/step - loss: 2.5457 - accuracy: 0.5912 - val_loss: 2.5300 - val_accuracy: 0.1648\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 1s 185ms/step - loss: 2.4908 - accuracy: 0.6354 - val_loss: 2.4755 - val_accuracy: 0.7363\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 1s 196ms/step - loss: 2.4371 - accuracy: 0.6961 - val_loss: 2.4226 - val_accuracy: 0.9890\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 1s 197ms/step - loss: 2.3845 - accuracy: 0.7680 - val_loss: 2.3713 - val_accuracy: 1.0000\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 1s 207ms/step - loss: 2.3339 - accuracy: 0.7376 - val_loss: 2.3214 - val_accuracy: 1.0000\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 1s 190ms/step - loss: 2.2839 - accuracy: 0.8149 - val_loss: 2.2727 - val_accuracy: 1.0000\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 1s 184ms/step - loss: 2.2362 - accuracy: 0.7901 - val_loss: 2.2249 - val_accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 1s 188ms/step - loss: 2.1888 - accuracy: 0.8343 - val_loss: 2.1781 - val_accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 1s 191ms/step - loss: 2.1431 - accuracy: 0.8564 - val_loss: 2.1321 - val_accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 1s 194ms/step - loss: 2.0992 - accuracy: 0.8785 - val_loss: 2.0870 - val_accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 1s 187ms/step - loss: 2.0555 - accuracy: 0.8729 - val_loss: 2.0427 - val_accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 1s 189ms/step - loss: 2.0131 - accuracy: 0.8895 - val_loss: 1.9991 - val_accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 1s 194ms/step - loss: 1.9730 - accuracy: 0.8812 - val_loss: 1.9564 - val_accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 1s 190ms/step - loss: 1.9318 - accuracy: 0.8978 - val_loss: 1.9145 - val_accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 1s 190ms/step - loss: 1.8925 - accuracy: 0.9199 - val_loss: 1.8735 - val_accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 1s 193ms/step - loss: 1.8540 - accuracy: 0.9309 - val_loss: 1.8335 - val_accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 1s 194ms/step - loss: 1.8165 - accuracy: 0.9309 - val_loss: 1.7945 - val_accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 1s 192ms/step - loss: 1.7798 - accuracy: 0.9558 - val_loss: 1.7566 - val_accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 1s 178ms/step - loss: 1.7442 - accuracy: 0.9448 - val_loss: 1.7196 - val_accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 1s 178ms/step - loss: 1.7091 - accuracy: 0.9669 - val_loss: 1.6836 - val_accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 1s 185ms/step - loss: 1.6750 - accuracy: 0.9669 - val_loss: 1.6486 - val_accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 1s 195ms/step - loss: 1.6414 - accuracy: 0.9751 - val_loss: 1.6144 - val_accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 1s 206ms/step - loss: 1.6088 - accuracy: 0.9779 - val_loss: 1.5810 - val_accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 1s 187ms/step - loss: 1.5767 - accuracy: 0.9751 - val_loss: 1.5485 - val_accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 1s 182ms/step - loss: 1.5452 - accuracy: 0.9807 - val_loss: 1.5165 - val_accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 1s 185ms/step - loss: 1.5148 - accuracy: 0.9807 - val_loss: 1.4852 - val_accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 1s 184ms/step - loss: 1.4846 - accuracy: 0.9917 - val_loss: 1.4547 - val_accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 1s 186ms/step - loss: 1.4552 - accuracy: 0.9890 - val_loss: 1.4248 - val_accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 1s 196ms/step - loss: 1.4269 - accuracy: 0.9945 - val_loss: 1.3956 - val_accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 1s 178ms/step - loss: 1.3982 - accuracy: 0.9945 - val_loss: 1.3670 - val_accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 1s 186ms/step - loss: 1.3706 - accuracy: 0.9972 - val_loss: 1.3391 - val_accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 1s 186ms/step - loss: 1.3436 - accuracy: 1.0000 - val_loss: 1.3118 - val_accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 1s 186ms/step - loss: 1.3170 - accuracy: 1.0000 - val_loss: 1.2849 - val_accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 1s 185ms/step - loss: 1.2907 - accuracy: 0.9945 - val_loss: 1.2586 - val_accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 1s 189ms/step - loss: 1.2652 - accuracy: 1.0000 - val_loss: 1.2331 - val_accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 1s 185ms/step - loss: 1.2403 - accuracy: 1.0000 - val_loss: 1.2081 - val_accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 1s 186ms/step - loss: 1.2155 - accuracy: 1.0000 - val_loss: 1.1835 - val_accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 1s 194ms/step - loss: 1.1913 - accuracy: 1.0000 - val_loss: 1.1592 - val_accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 1s 179ms/step - loss: 1.1676 - accuracy: 1.0000 - val_loss: 1.1354 - val_accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 1s 185ms/step - loss: 1.1443 - accuracy: 1.0000 - val_loss: 1.1124 - val_accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 1s 194ms/step - loss: 1.1215 - accuracy: 1.0000 - val_loss: 1.0897 - val_accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 1s 200ms/step - loss: 1.0991 - accuracy: 1.0000 - val_loss: 1.0674 - val_accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 1s 186ms/step - loss: 1.0771 - accuracy: 1.0000 - val_loss: 1.0456 - val_accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 1s 194ms/step - loss: 1.0557 - accuracy: 1.0000 - val_loss: 1.0241 - val_accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 1s 188ms/step - loss: 1.0343 - accuracy: 1.0000 - val_loss: 1.0030 - val_accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.0199 - accuracy: 1.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 41>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     36\u001b[0m x_train, x_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(data_matrix, Num_labels, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.05\u001b[39m, random_state\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m500\u001b[39m))\n\u001b[0;32m     39\u001b[0m y_train \u001b[38;5;241m=\u001b[39m to_categorical(y_train)\n\u001b[1;32m---> 41\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m126\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1402\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1403\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1404\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   1405\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[0;32m   1406\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   1407\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m   1408\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1409\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1410\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1411\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2450\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2451\u001b[0m   (graph_function,\n\u001b[0;32m   2452\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2454\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1856\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1857\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1858\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1859\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1860\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1861\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1862\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1863\u001b[0m     args,\n\u001b[0;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1865\u001b[0m     executing_eagerly)\n\u001b[0;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    496\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 497\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    503\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    504\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    505\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    506\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    509\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    510\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "from keras.regularizers import l2\n",
    "                 \n",
    "Lambda= 3e-2                                           \n",
    "\n",
    "# Build the Model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(input_shape=(Lim, 4), units=16,\n",
    "               activation='tanh', \n",
    "               kernel_regularizer=l2(Lambda), recurrent_regularizer=l2(Lambda),\n",
    "               return_sequences=True,\n",
    "  \n",
    "              ))\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "model.add(LSTM(units=8,\n",
    "               activation='tanh', \n",
    "               kernel_regularizer=l2(Lambda), recurrent_regularizer=l2(Lambda),\n",
    "               return_sequences=True, \n",
    "                \n",
    "              ))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LSTM(units=8,\n",
    "               activation='tanh', \n",
    "               kernel_regularizer=l2(Lambda), recurrent_regularizer=l2(Lambda),\n",
    "               return_sequences=False, \n",
    "\n",
    "              ))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(units=2, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              metrics=['accuracy'],\n",
    "              optimizer='adam')\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(data_matrix, Num_labels, test_size=0.05, random_state=np.random.randint(500))\n",
    "\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "                    epochs=100,\n",
    "                    batch_size=126,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6a8b63f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]]\n",
      "1/1 [==============================] - 1s 877ms/step\n",
      "[[0.3 0.6]\n",
      " [0.3 0.6]\n",
      " [0.3 0.6]\n",
      " [0.3 0.6]\n",
      " [0.3 0.6]\n",
      " [0.3 0.6]\n",
      " [0.3 0.6]\n",
      " [0.4 0.6]\n",
      " [0.4 0.6]\n",
      " [0.4 0.6]\n",
      " [0.4 0.6]\n",
      " [0.3 0.6]\n",
      " [0.3 0.6]\n",
      " [0.3 0.6]\n",
      " [0.3 0.6]\n",
      " [0.3 0.6]\n",
      " [0.3 0.6]\n",
      " [0.3 0.6]\n",
      " [0.3 0.6]\n",
      " [0.3 0.6]\n",
      " [0.4 0.6]\n",
      " [0.4 0.6]\n",
      " [0.3 0.6]\n",
      " [0.3 0.6]]\n"
     ]
    }
   ],
   "source": [
    "print(to_categorical(y_test))\n",
    "print(np.round(model.predict(x_test),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e80eeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelsMF=[]\n",
    "for i in range(len(data)):\n",
    "    if data['Sexe'].iloc[i]=='MÃ¢le':\n",
    "        labelsMF.append(0)\n",
    "    else:\n",
    "        labelsMF.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b572557b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9062805208898536\n",
      "0.90625\n",
      "0.9062398263700489\n"
     ]
    }
   ],
   "source": [
    "#Male VS Female RANDOMFOREST\n",
    "\n",
    "# Good Performance for scaling == False !  90%~\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(MFCC_H, labelsMF, test_size=0.2, random_state=np.random.randint(500))\n",
    "\n",
    "#print(y_train)\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=1000,\n",
    "                               random_state=25)\n",
    "\n",
    "    \n",
    "model.fit(x_train, y_train)\n",
    "prediction= model.predict(x_test)\n",
    "f1= f1_score(y_test,prediction,average='weighted')\n",
    "\n",
    "\n",
    "    \n",
    "print(f1)\n",
    "print(f1_score(y_test,prediction,average='micro'))\n",
    "print(f1_score(y_test,prediction,average='macro'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d767d8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling=False\n",
    "\n",
    "def scaler(array):\n",
    "    scaler = MinMaxScaler()\n",
    "    array=array.reshape(-1,1)\n",
    "    scaler.fit(array)\n",
    "    array=scaler.transform(array)\n",
    "    return array\n",
    "\n",
    "sample_length= []\n",
    "\n",
    "\n",
    "MFCC=np.zeros((len(fnames),Lim,20))\n",
    "CONTRAST=np.zeros((len(fnames),Lim,7))\n",
    "\n",
    "\n",
    "Lim = min(Length)\n",
    "\n",
    "for i in range(len(fnames)):\n",
    "    \n",
    "    \n",
    "    \n",
    "    wav_fname = pjoin(data_dir,actors[i], fnames[i])\n",
    "    samplerate, data_sample = wavfile.read(wav_fname)\n",
    "    number_of_channels = 1\n",
    "    length = data_sample.shape[0] / samplerate\n",
    "    sample_length.append(length)\n",
    "  \n",
    "    Data=np.array(data_sample).astype(float)\n",
    "    lib_STFT=np.abs(librosa.stft(Data)) \n",
    "    \n",
    "    \n",
    "\n",
    "    if scaling==True: \n",
    "        \n",
    "        mfcc_h = librosa.feature.mfcc(y=Data)\n",
    "        contrast=librosa.feature.spectral_contrast(S=lib_STFT)\n",
    "        \n",
    "        for k in range(20):\n",
    "            \n",
    "            mfcc_h[k] = scaler(mfcc_h[k]).flatten()\n",
    "        for k in range(7):\n",
    "            contrast[k] = scaler(contrast[k]).flatten()\n",
    "    if scaling==False:\n",
    "\n",
    "        mfcc_h = librosa.feature.mfcc(y=Data)\n",
    "        contrast=librosa.feature.spectral_contrast(S=lib_STFT)\n",
    "\n",
    "\n",
    "    if len(mfcc_h[0])>min(Length):\n",
    "        \n",
    "        aa=np.arange(Lim,len(mfcc_h[0]))\n",
    "        contrast=np.delete(contrast,aa,axis=1).T\n",
    "        mfcc_h=np.delete(mfcc_h,aa,axis=1).T\n",
    "        MFCC[i] = np.vstack((mfcc_h))\n",
    "        CONTRAST[i] = np.vstack((contrast))\n",
    "\n",
    "\n",
    "    else:\n",
    "         MFCC[i] = np.vstack((mfcc_h.T))\n",
    "         CONTRAST[i] = np.vstack((contrast.T))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cda285a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "3/3 [==============================] - 6s 506ms/step - loss: 3.0686 - accuracy: 0.4828 - val_loss: 2.8877 - val_accuracy: 0.5205\n",
      "Epoch 2/150\n",
      "3/3 [==============================] - 1s 290ms/step - loss: 2.9790 - accuracy: 0.4793 - val_loss: 2.8391 - val_accuracy: 0.5205\n",
      "Epoch 3/150\n",
      "3/3 [==============================] - 1s 290ms/step - loss: 2.8848 - accuracy: 0.5276 - val_loss: 2.7921 - val_accuracy: 0.5205\n",
      "Epoch 4/150\n",
      "3/3 [==============================] - 1s 290ms/step - loss: 2.8367 - accuracy: 0.5483 - val_loss: 2.7465 - val_accuracy: 0.5205\n",
      "Epoch 5/150\n",
      "3/3 [==============================] - 1s 311ms/step - loss: 2.7714 - accuracy: 0.5586 - val_loss: 2.7021 - val_accuracy: 0.5205\n",
      "Epoch 6/150\n",
      "3/3 [==============================] - 1s 284ms/step - loss: 2.7051 - accuracy: 0.5552 - val_loss: 2.6585 - val_accuracy: 0.5205\n",
      "Epoch 7/150\n",
      "3/3 [==============================] - 1s 292ms/step - loss: 2.6476 - accuracy: 0.5517 - val_loss: 2.6154 - val_accuracy: 0.5205\n",
      "Epoch 8/150\n",
      "3/3 [==============================] - 1s 293ms/step - loss: 2.6104 - accuracy: 0.5310 - val_loss: 2.5746 - val_accuracy: 0.5205\n",
      "Epoch 9/150\n",
      "3/3 [==============================] - 1s 290ms/step - loss: 2.5455 - accuracy: 0.5724 - val_loss: 2.5377 - val_accuracy: 0.5205\n",
      "Epoch 10/150\n",
      "3/3 [==============================] - 1s 294ms/step - loss: 2.5071 - accuracy: 0.5724 - val_loss: 2.5013 - val_accuracy: 0.5205\n",
      "Epoch 11/150\n",
      "3/3 [==============================] - 1s 297ms/step - loss: 2.4720 - accuracy: 0.5621 - val_loss: 2.4651 - val_accuracy: 0.5205\n",
      "Epoch 12/150\n",
      "3/3 [==============================] - 1s 312ms/step - loss: 2.4328 - accuracy: 0.5517 - val_loss: 2.4294 - val_accuracy: 0.5205\n",
      "Epoch 13/150\n",
      "3/3 [==============================] - 1s 301ms/step - loss: 2.3997 - accuracy: 0.5724 - val_loss: 2.3943 - val_accuracy: 0.5205\n",
      "Epoch 14/150\n",
      "3/3 [==============================] - 1s 290ms/step - loss: 2.3597 - accuracy: 0.5724 - val_loss: 2.3597 - val_accuracy: 0.5205\n",
      "Epoch 15/150\n",
      "3/3 [==============================] - 1s 289ms/step - loss: 2.3281 - accuracy: 0.5759 - val_loss: 2.3254 - val_accuracy: 0.5205\n",
      "Epoch 16/150\n",
      "3/3 [==============================] - 1s 282ms/step - loss: 2.2818 - accuracy: 0.5759 - val_loss: 2.2918 - val_accuracy: 0.5205\n",
      "Epoch 17/150\n",
      "3/3 [==============================] - 1s 289ms/step - loss: 2.2451 - accuracy: 0.5828 - val_loss: 2.2589 - val_accuracy: 0.5205\n",
      "Epoch 18/150\n",
      "3/3 [==============================] - 1s 289ms/step - loss: 2.2122 - accuracy: 0.5759 - val_loss: 2.2267 - val_accuracy: 0.5205\n",
      "Epoch 19/150\n",
      "3/3 [==============================] - 1s 289ms/step - loss: 2.1800 - accuracy: 0.5759 - val_loss: 2.1951 - val_accuracy: 0.5205\n",
      "Epoch 20/150\n",
      "3/3 [==============================] - 1s 298ms/step - loss: 2.1423 - accuracy: 0.5828 - val_loss: 2.1644 - val_accuracy: 0.5205\n",
      "Epoch 21/150\n",
      "3/3 [==============================] - 1s 294ms/step - loss: 2.1092 - accuracy: 0.5862 - val_loss: 2.1343 - val_accuracy: 0.5205\n",
      "Epoch 22/150\n",
      "3/3 [==============================] - 1s 290ms/step - loss: 2.0803 - accuracy: 0.5828 - val_loss: 2.1047 - val_accuracy: 0.5205\n",
      "Epoch 23/150\n",
      "3/3 [==============================] - 1s 289ms/step - loss: 2.0461 - accuracy: 0.5862 - val_loss: 2.0756 - val_accuracy: 0.5205\n",
      "Epoch 24/150\n",
      "3/3 [==============================] - 1s 297ms/step - loss: 2.0156 - accuracy: 0.5862 - val_loss: 2.0471 - val_accuracy: 0.5205\n",
      "Epoch 25/150\n",
      "3/3 [==============================] - 1s 291ms/step - loss: 1.9864 - accuracy: 0.5897 - val_loss: 2.0191 - val_accuracy: 0.5205\n",
      "Epoch 26/150\n",
      "3/3 [==============================] - 1s 290ms/step - loss: 1.9595 - accuracy: 0.5897 - val_loss: 1.9918 - val_accuracy: 0.5205\n",
      "Epoch 27/150\n",
      "3/3 [==============================] - 1s 289ms/step - loss: 1.9278 - accuracy: 0.5897 - val_loss: 1.9650 - val_accuracy: 0.5205\n",
      "Epoch 28/150\n",
      "3/3 [==============================] - 1s 289ms/step - loss: 1.8999 - accuracy: 0.5897 - val_loss: 1.9387 - val_accuracy: 0.5205\n",
      "Epoch 29/150\n",
      "3/3 [==============================] - 1s 290ms/step - loss: 1.8707 - accuracy: 0.5931 - val_loss: 1.9130 - val_accuracy: 0.5205\n",
      "Epoch 30/150\n",
      "3/3 [==============================] - 1s 290ms/step - loss: 1.8432 - accuracy: 0.5966 - val_loss: 1.8877 - val_accuracy: 0.5205\n",
      "Epoch 31/150\n",
      "3/3 [==============================] - 1s 289ms/step - loss: 1.8183 - accuracy: 0.6000 - val_loss: 1.8630 - val_accuracy: 0.5205\n",
      "Epoch 32/150\n",
      "3/3 [==============================] - 1s 290ms/step - loss: 1.7916 - accuracy: 0.6000 - val_loss: 1.8388 - val_accuracy: 0.5205\n",
      "Epoch 33/150\n",
      "3/3 [==============================] - 1s 290ms/step - loss: 1.7666 - accuracy: 0.6000 - val_loss: 1.8151 - val_accuracy: 0.5205\n",
      "Epoch 34/150\n",
      "3/3 [==============================] - 1s 297ms/step - loss: 1.7447 - accuracy: 0.6000 - val_loss: 1.7919 - val_accuracy: 0.5205\n",
      "Epoch 35/150\n",
      "3/3 [==============================] - 1s 290ms/step - loss: 1.7187 - accuracy: 0.6000 - val_loss: 1.7692 - val_accuracy: 0.5205\n",
      "Epoch 36/150\n",
      "3/3 [==============================] - 1s 289ms/step - loss: 1.6971 - accuracy: 0.6000 - val_loss: 1.7470 - val_accuracy: 0.5205\n",
      "Epoch 37/150\n",
      "3/3 [==============================] - 1s 291ms/step - loss: 1.6731 - accuracy: 0.5931 - val_loss: 1.7253 - val_accuracy: 0.5205\n",
      "Epoch 38/150\n",
      "3/3 [==============================] - 1s 290ms/step - loss: 1.6543 - accuracy: 0.6000 - val_loss: 1.7040 - val_accuracy: 0.5205\n",
      "Epoch 39/150\n",
      "3/3 [==============================] - 1s 298ms/step - loss: 1.6335 - accuracy: 0.6000 - val_loss: 1.6831 - val_accuracy: 0.5205\n",
      "Epoch 40/150\n",
      "3/3 [==============================] - 1s 290ms/step - loss: 1.6071 - accuracy: 0.6000 - val_loss: 1.6626 - val_accuracy: 0.5205\n",
      "Epoch 41/150\n",
      "3/3 [==============================] - 1s 291ms/step - loss: 1.5865 - accuracy: 0.5966 - val_loss: 1.6426 - val_accuracy: 0.5205\n",
      "Epoch 42/150\n",
      "3/3 [==============================] - 1s 292ms/step - loss: 1.5688 - accuracy: 0.6000 - val_loss: 1.6231 - val_accuracy: 0.5205\n",
      "Epoch 43/150\n",
      "3/3 [==============================] - 1s 290ms/step - loss: 1.5440 - accuracy: 0.5966 - val_loss: 1.6041 - val_accuracy: 0.5205\n",
      "Epoch 44/150\n",
      "3/3 [==============================] - 1s 291ms/step - loss: 1.5214 - accuracy: 0.6103 - val_loss: 1.5853 - val_accuracy: 0.5205\n",
      "Epoch 45/150\n",
      "3/3 [==============================] - 1s 298ms/step - loss: 1.5018 - accuracy: 0.6172 - val_loss: 1.5670 - val_accuracy: 0.5205\n",
      "Epoch 46/150\n",
      "3/3 [==============================] - 1s 307ms/step - loss: 1.4824 - accuracy: 0.6103 - val_loss: 1.5491 - val_accuracy: 0.5205\n",
      "Epoch 47/150\n",
      "3/3 [==============================] - 1s 293ms/step - loss: 1.4652 - accuracy: 0.6034 - val_loss: 1.5317 - val_accuracy: 0.5205\n",
      "Epoch 48/150\n",
      "3/3 [==============================] - 1s 297ms/step - loss: 1.4538 - accuracy: 0.6000 - val_loss: 1.5146 - val_accuracy: 0.5205\n",
      "Epoch 49/150\n",
      "3/3 [==============================] - 1s 290ms/step - loss: 1.4303 - accuracy: 0.6000 - val_loss: 1.4978 - val_accuracy: 0.5205\n",
      "Epoch 50/150\n",
      "3/3 [==============================] - 1s 291ms/step - loss: 1.4134 - accuracy: 0.6103 - val_loss: 1.4814 - val_accuracy: 0.5205\n",
      "Epoch 51/150\n",
      "3/3 [==============================] - 1s 297ms/step - loss: 1.3984 - accuracy: 0.6034 - val_loss: 1.4653 - val_accuracy: 0.5205\n",
      "Epoch 52/150\n",
      "3/3 [==============================] - 1s 296ms/step - loss: 1.3815 - accuracy: 0.6138 - val_loss: 1.4496 - val_accuracy: 0.5205\n",
      "Epoch 53/150\n",
      "3/3 [==============================] - 1s 320ms/step - loss: 1.3656 - accuracy: 0.6069 - val_loss: 1.4341 - val_accuracy: 0.5205\n",
      "Epoch 54/150\n",
      "3/3 [==============================] - 1s 303ms/step - loss: 1.3452 - accuracy: 0.6069 - val_loss: 1.4190 - val_accuracy: 0.5205\n",
      "Epoch 55/150\n",
      "3/3 [==============================] - 1s 289ms/step - loss: 1.3325 - accuracy: 0.6069 - val_loss: 1.4042 - val_accuracy: 0.5205\n",
      "Epoch 56/150\n",
      "3/3 [==============================] - 1s 290ms/step - loss: 1.3173 - accuracy: 0.6103 - val_loss: 1.3898 - val_accuracy: 0.5205\n",
      "Epoch 57/150\n",
      "3/3 [==============================] - 1s 290ms/step - loss: 1.3061 - accuracy: 0.6000 - val_loss: 1.3758 - val_accuracy: 0.5205\n",
      "Epoch 58/150\n",
      "3/3 [==============================] - 1s 298ms/step - loss: 1.2869 - accuracy: 0.6103 - val_loss: 1.3621 - val_accuracy: 0.5205\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/150\n",
      "3/3 [==============================] - 1s 290ms/step - loss: 1.2828 - accuracy: 0.6069 - val_loss: 1.3487 - val_accuracy: 0.5205\n",
      "Epoch 60/150\n",
      "3/3 [==============================] - 1s 290ms/step - loss: 1.2607 - accuracy: 0.6069 - val_loss: 1.3356 - val_accuracy: 0.5205\n",
      "Epoch 61/150\n",
      "3/3 [==============================] - 1s 293ms/step - loss: 1.2473 - accuracy: 0.6069 - val_loss: 1.3227 - val_accuracy: 0.5205\n",
      "Epoch 62/150\n",
      "3/3 [==============================] - 1s 291ms/step - loss: 1.2323 - accuracy: 0.6069 - val_loss: 1.3101 - val_accuracy: 0.5205\n",
      "Epoch 63/150\n",
      "3/3 [==============================] - 1s 289ms/step - loss: 1.2194 - accuracy: 0.6000 - val_loss: 1.2977 - val_accuracy: 0.5205\n",
      "Epoch 64/150\n",
      "3/3 [==============================] - 1s 290ms/step - loss: 1.2064 - accuracy: 0.6069 - val_loss: 1.2857 - val_accuracy: 0.5205\n",
      "Epoch 65/150\n",
      "3/3 [==============================] - 1s 290ms/step - loss: 1.1949 - accuracy: 0.6172 - val_loss: 1.2738 - val_accuracy: 0.5205\n",
      "Epoch 66/150\n",
      "3/3 [==============================] - 1s 292ms/step - loss: 1.1805 - accuracy: 0.6172 - val_loss: 1.2623 - val_accuracy: 0.5205\n",
      "Epoch 67/150\n",
      "3/3 [==============================] - 1s 290ms/step - loss: 1.1711 - accuracy: 0.6000 - val_loss: 1.2510 - val_accuracy: 0.5205\n",
      "Epoch 68/150\n",
      "3/3 [==============================] - 1s 290ms/step - loss: 1.1599 - accuracy: 0.6000 - val_loss: 1.2399 - val_accuracy: 0.5205\n",
      "Epoch 69/150\n",
      "3/3 [==============================] - 1s 306ms/step - loss: 1.1484 - accuracy: 0.6000 - val_loss: 1.2291 - val_accuracy: 0.5205\n",
      "Epoch 70/150\n",
      "3/3 [==============================] - 1s 290ms/step - loss: 1.1417 - accuracy: 0.6069 - val_loss: 1.2187 - val_accuracy: 0.5205\n",
      "Epoch 71/150\n",
      "3/3 [==============================] - 1s 291ms/step - loss: 1.1267 - accuracy: 0.6103 - val_loss: 1.2084 - val_accuracy: 0.5205\n",
      "Epoch 72/150\n",
      "3/3 [==============================] - 1s 290ms/step - loss: 1.1157 - accuracy: 0.6172 - val_loss: 1.1983 - val_accuracy: 0.5205\n",
      "Epoch 73/150\n",
      "3/3 [==============================] - 1s 291ms/step - loss: 1.1049 - accuracy: 0.6345 - val_loss: 1.1886 - val_accuracy: 0.5205\n",
      "Epoch 74/150\n",
      "3/3 [==============================] - 1s 296ms/step - loss: 1.0984 - accuracy: 0.6207 - val_loss: 1.1792 - val_accuracy: 0.5205\n",
      "Epoch 75/150\n",
      "3/3 [==============================] - 1s 290ms/step - loss: 1.0823 - accuracy: 0.6138 - val_loss: 1.1698 - val_accuracy: 0.5205\n",
      "Epoch 76/150\n",
      "3/3 [==============================] - 1s 290ms/step - loss: 1.0710 - accuracy: 0.6103 - val_loss: 1.1607 - val_accuracy: 0.5205\n",
      "Epoch 77/150\n",
      "3/3 [==============================] - 1s 290ms/step - loss: 1.0645 - accuracy: 0.6138 - val_loss: 1.1519 - val_accuracy: 0.5205\n",
      "Epoch 78/150\n",
      "3/3 [==============================] - 1s 298ms/step - loss: 1.0569 - accuracy: 0.6207 - val_loss: 1.1433 - val_accuracy: 0.5205\n",
      "Epoch 79/150\n",
      "3/3 [==============================] - 1s 290ms/step - loss: 1.0670 - accuracy: 0.5862 - val_loss: 1.1347 - val_accuracy: 0.5205\n",
      "Epoch 80/150\n",
      "3/3 [==============================] - 1s 298ms/step - loss: 1.0392 - accuracy: 0.6172 - val_loss: 1.1262 - val_accuracy: 0.5205\n",
      "Epoch 81/150\n",
      "3/3 [==============================] - 1s 297ms/step - loss: 1.0325 - accuracy: 0.6138 - val_loss: 1.1179 - val_accuracy: 0.5205\n",
      "Epoch 82/150\n",
      "3/3 [==============================] - 1s 291ms/step - loss: 1.0204 - accuracy: 0.6138 - val_loss: 1.1099 - val_accuracy: 0.5205\n",
      "Epoch 83/150\n",
      "3/3 [==============================] - 1s 289ms/step - loss: 1.0125 - accuracy: 0.6172 - val_loss: 1.1022 - val_accuracy: 0.5205\n",
      "Epoch 84/150\n",
      "3/3 [==============================] - 1s 298ms/step - loss: 1.0031 - accuracy: 0.6172 - val_loss: 1.0946 - val_accuracy: 0.5205\n",
      "Epoch 85/150\n",
      "3/3 [==============================] - 1s 290ms/step - loss: 0.9965 - accuracy: 0.6103 - val_loss: 1.0874 - val_accuracy: 0.5205\n",
      "Epoch 86/150\n",
      "3/3 [==============================] - 1s 290ms/step - loss: 0.9862 - accuracy: 0.6138 - val_loss: 1.0803 - val_accuracy: 0.5205\n",
      "Epoch 87/150\n",
      "3/3 [==============================] - 1s 298ms/step - loss: 0.9828 - accuracy: 0.6138 - val_loss: 1.0732 - val_accuracy: 0.5205\n",
      "Epoch 88/150\n",
      "3/3 [==============================] - 1s 297ms/step - loss: 0.9718 - accuracy: 0.6138 - val_loss: 1.0659 - val_accuracy: 0.5342\n",
      "Epoch 89/150\n",
      "3/3 [==============================] - 1s 290ms/step - loss: 0.9710 - accuracy: 0.6138 - val_loss: 1.0588 - val_accuracy: 0.5342\n",
      "Epoch 90/150\n",
      "3/3 [==============================] - 1s 289ms/step - loss: 0.9630 - accuracy: 0.6138 - val_loss: 1.0518 - val_accuracy: 0.5342\n",
      "Epoch 91/150\n",
      "3/3 [==============================] - 1s 290ms/step - loss: 0.9547 - accuracy: 0.6138 - val_loss: 1.0452 - val_accuracy: 0.5342\n",
      "Epoch 92/150\n",
      "3/3 [==============================] - 1s 290ms/step - loss: 0.9506 - accuracy: 0.6138 - val_loss: 1.0389 - val_accuracy: 0.5342\n",
      "Epoch 93/150\n",
      "3/3 [==============================] - 1s 298ms/step - loss: 0.9399 - accuracy: 0.6172 - val_loss: 1.0323 - val_accuracy: 0.5342\n",
      "Epoch 94/150\n",
      "3/3 [==============================] - 1s 291ms/step - loss: 0.9324 - accuracy: 0.6172 - val_loss: 1.0261 - val_accuracy: 0.5342\n",
      "Epoch 95/150\n",
      "3/3 [==============================] - 1s 290ms/step - loss: 0.9268 - accuracy: 0.6207 - val_loss: 1.0207 - val_accuracy: 0.5342\n",
      "Epoch 96/150\n",
      "3/3 [==============================] - 1s 298ms/step - loss: 0.9170 - accuracy: 0.6276 - val_loss: 1.0147 - val_accuracy: 0.5342\n",
      "Epoch 97/150\n",
      "3/3 [==============================] - 1s 290ms/step - loss: 0.9088 - accuracy: 0.6276 - val_loss: 1.0084 - val_accuracy: 0.5342\n",
      "Epoch 98/150\n",
      "3/3 [==============================] - 1s 307ms/step - loss: 0.9041 - accuracy: 0.6207 - val_loss: 1.0027 - val_accuracy: 0.5205\n",
      "Epoch 99/150\n",
      "3/3 [==============================] - 1s 306ms/step - loss: 0.8959 - accuracy: 0.6241 - val_loss: 0.9978 - val_accuracy: 0.5342\n",
      "Epoch 100/150\n",
      "3/3 [==============================] - 1s 284ms/step - loss: 0.8903 - accuracy: 0.6276 - val_loss: 0.9932 - val_accuracy: 0.5342\n",
      "Epoch 101/150\n",
      "3/3 [==============================] - 1s 298ms/step - loss: 0.8839 - accuracy: 0.6276 - val_loss: 0.9883 - val_accuracy: 0.5342\n",
      "Epoch 102/150\n",
      "3/3 [==============================] - 1s 290ms/step - loss: 0.8818 - accuracy: 0.6310 - val_loss: 0.9831 - val_accuracy: 0.5205\n",
      "Epoch 103/150\n",
      "3/3 [==============================] - 1s 289ms/step - loss: 0.8764 - accuracy: 0.6310 - val_loss: 0.9777 - val_accuracy: 0.5205\n",
      "Epoch 104/150\n",
      "3/3 [==============================] - 1s 298ms/step - loss: 0.8718 - accuracy: 0.6276 - val_loss: 0.9721 - val_accuracy: 0.5205\n",
      "Epoch 105/150\n",
      "3/3 [==============================] - 1s 312ms/step - loss: 0.8592 - accuracy: 0.6310 - val_loss: 0.9667 - val_accuracy: 0.5205\n",
      "Epoch 106/150\n",
      "3/3 [==============================] - 1s 305ms/step - loss: 0.8598 - accuracy: 0.6276 - val_loss: 0.9621 - val_accuracy: 0.5342\n",
      "Epoch 107/150\n",
      "3/3 [==============================] - 1s 304ms/step - loss: 0.8529 - accuracy: 0.6310 - val_loss: 0.9581 - val_accuracy: 0.5342\n",
      "Epoch 108/150\n",
      "3/3 [==============================] - 1s 302ms/step - loss: 0.8498 - accuracy: 0.6241 - val_loss: 0.9540 - val_accuracy: 0.5342\n",
      "Epoch 109/150\n",
      "3/3 [==============================] - 1s 292ms/step - loss: 0.8433 - accuracy: 0.6345 - val_loss: 0.9494 - val_accuracy: 0.5342\n",
      "Epoch 110/150\n",
      "3/3 [==============================] - 1s 290ms/step - loss: 0.8386 - accuracy: 0.6310 - val_loss: 0.9454 - val_accuracy: 0.5205\n",
      "Epoch 111/150\n",
      "3/3 [==============================] - 1s 299ms/step - loss: 0.8456 - accuracy: 0.6241 - val_loss: 0.9438 - val_accuracy: 0.5342\n",
      "Epoch 112/150\n",
      "3/3 [==============================] - 1s 290ms/step - loss: 0.8356 - accuracy: 0.6241 - val_loss: 0.9444 - val_accuracy: 0.5342\n",
      "Epoch 113/150\n",
      "3/3 [==============================] - 1s 298ms/step - loss: 0.8390 - accuracy: 0.6241 - val_loss: 0.9389 - val_accuracy: 0.5342\n",
      "Epoch 114/150\n",
      "3/3 [==============================] - 1s 302ms/step - loss: 0.8348 - accuracy: 0.6310 - val_loss: 0.9315 - val_accuracy: 0.5342\n",
      "Epoch 115/150\n",
      "3/3 [==============================] - 1s 300ms/step - loss: 0.8279 - accuracy: 0.6310 - val_loss: 0.9242 - val_accuracy: 0.5342\n",
      "Epoch 116/150\n",
      "3/3 [==============================] - 1s 300ms/step - loss: 0.8227 - accuracy: 0.6310 - val_loss: 0.9188 - val_accuracy: 0.5205\n",
      "Epoch 117/150\n",
      "3/3 [==============================] - 1s 299ms/step - loss: 0.8172 - accuracy: 0.6310 - val_loss: 0.9154 - val_accuracy: 0.5616\n",
      "Epoch 118/150\n",
      "3/3 [==============================] - 1s 297ms/step - loss: 0.8117 - accuracy: 0.6310 - val_loss: 0.9139 - val_accuracy: 0.5616\n",
      "Epoch 119/150\n",
      "3/3 [==============================] - 1s 299ms/step - loss: 0.8097 - accuracy: 0.6310 - val_loss: 0.9136 - val_accuracy: 0.5753\n",
      "Epoch 120/150\n",
      "3/3 [==============================] - 1s 290ms/step - loss: 0.8009 - accuracy: 0.6276 - val_loss: 0.9135 - val_accuracy: 0.4521\n",
      "Epoch 121/150\n",
      "3/3 [==============================] - 1s 298ms/step - loss: 0.7970 - accuracy: 0.6345 - val_loss: 0.9118 - val_accuracy: 0.5616\n",
      "Epoch 122/150\n",
      "3/3 [==============================] - 1s 295ms/step - loss: 0.7946 - accuracy: 0.6414 - val_loss: 0.9093 - val_accuracy: 0.5616\n",
      "Epoch 123/150\n",
      "3/3 [==============================] - 1s 295ms/step - loss: 0.7894 - accuracy: 0.6310 - val_loss: 0.9056 - val_accuracy: 0.5616\n",
      "Epoch 124/150\n",
      "3/3 [==============================] - 1s 286ms/step - loss: 0.7895 - accuracy: 0.6379 - val_loss: 0.9012 - val_accuracy: 0.5342\n",
      "Epoch 125/150\n",
      "3/3 [==============================] - 1s 282ms/step - loss: 0.7879 - accuracy: 0.6345 - val_loss: 0.8966 - val_accuracy: 0.5479\n",
      "Epoch 126/150\n",
      "3/3 [==============================] - 1s 291ms/step - loss: 0.7802 - accuracy: 0.6414 - val_loss: 0.8939 - val_accuracy: 0.5479\n",
      "Epoch 127/150\n",
      "3/3 [==============================] - 1s 290ms/step - loss: 0.7766 - accuracy: 0.6379 - val_loss: 0.8921 - val_accuracy: 0.5479\n",
      "Epoch 128/150\n",
      "3/3 [==============================] - 1s 292ms/step - loss: 0.7739 - accuracy: 0.6345 - val_loss: 0.8913 - val_accuracy: 0.5616\n",
      "Epoch 129/150\n",
      "3/3 [==============================] - 1s 295ms/step - loss: 0.7715 - accuracy: 0.6310 - val_loss: 0.8903 - val_accuracy: 0.5616\n",
      "Epoch 130/150\n",
      "3/3 [==============================] - 1s 299ms/step - loss: 0.7673 - accuracy: 0.6379 - val_loss: 0.8861 - val_accuracy: 0.5616\n",
      "Epoch 131/150\n",
      "3/3 [==============================] - 1s 293ms/step - loss: 0.7626 - accuracy: 0.6448 - val_loss: 0.8816 - val_accuracy: 0.5616\n",
      "Epoch 132/150\n",
      "3/3 [==============================] - 1s 290ms/step - loss: 0.7831 - accuracy: 0.6379 - val_loss: 0.8783 - val_accuracy: 0.5616\n",
      "Epoch 133/150\n",
      "3/3 [==============================] - 1s 298ms/step - loss: 0.7637 - accuracy: 0.6379 - val_loss: 0.8737 - val_accuracy: 0.5342\n",
      "Epoch 134/150\n",
      "3/3 [==============================] - 1s 290ms/step - loss: 0.7578 - accuracy: 0.6379 - val_loss: 0.8698 - val_accuracy: 0.5205\n",
      "Epoch 135/150\n",
      "3/3 [==============================] - 1s 290ms/step - loss: 0.7460 - accuracy: 0.6448 - val_loss: 0.8665 - val_accuracy: 0.5205\n",
      "Epoch 136/150\n",
      "3/3 [==============================] - 1s 291ms/step - loss: 0.7481 - accuracy: 0.6448 - val_loss: 0.8630 - val_accuracy: 0.5205\n",
      "Epoch 137/150\n",
      "3/3 [==============================] - 1s 293ms/step - loss: 0.7464 - accuracy: 0.6517 - val_loss: 0.8615 - val_accuracy: 0.5205\n",
      "Epoch 138/150\n",
      "3/3 [==============================] - 1s 290ms/step - loss: 0.7405 - accuracy: 0.6448 - val_loss: 0.8627 - val_accuracy: 0.5205\n",
      "Epoch 139/150\n",
      "3/3 [==============================] - 1s 297ms/step - loss: 0.7388 - accuracy: 0.6448 - val_loss: 0.8637 - val_accuracy: 0.5205\n",
      "Epoch 140/150\n",
      "3/3 [==============================] - 1s 290ms/step - loss: 0.7356 - accuracy: 0.6517 - val_loss: 0.8628 - val_accuracy: 0.5205\n",
      "Epoch 141/150\n",
      "3/3 [==============================] - 1s 294ms/step - loss: 0.7406 - accuracy: 0.6517 - val_loss: 0.8616 - val_accuracy: 0.5205\n",
      "Epoch 142/150\n",
      "3/3 [==============================] - 1s 289ms/step - loss: 0.7379 - accuracy: 0.6483 - val_loss: 0.8599 - val_accuracy: 0.5205\n",
      "Epoch 143/150\n",
      "3/3 [==============================] - 1s 290ms/step - loss: 0.7276 - accuracy: 0.6517 - val_loss: 0.8570 - val_accuracy: 0.5205\n",
      "Epoch 144/150\n",
      "3/3 [==============================] - 1s 298ms/step - loss: 0.7281 - accuracy: 0.6448 - val_loss: 0.8553 - val_accuracy: 0.5205\n",
      "Epoch 145/150\n",
      "3/3 [==============================] - 1s 306ms/step - loss: 0.7270 - accuracy: 0.6448 - val_loss: 0.8537 - val_accuracy: 0.5205\n",
      "Epoch 146/150\n",
      "3/3 [==============================] - 1s 290ms/step - loss: 0.7260 - accuracy: 0.6448 - val_loss: 0.8542 - val_accuracy: 0.5205\n",
      "Epoch 147/150\n",
      "3/3 [==============================] - 1s 289ms/step - loss: 0.7240 - accuracy: 0.6448 - val_loss: 0.8541 - val_accuracy: 0.5205\n",
      "Epoch 148/150\n",
      "3/3 [==============================] - 1s 298ms/step - loss: 0.7255 - accuracy: 0.6414 - val_loss: 0.8522 - val_accuracy: 0.5205\n",
      "Epoch 149/150\n",
      "3/3 [==============================] - 1s 292ms/step - loss: 0.7219 - accuracy: 0.6448 - val_loss: 0.8468 - val_accuracy: 0.5205\n",
      "Epoch 150/150\n",
      "3/3 [==============================] - 1s 290ms/step - loss: 0.7181 - accuracy: 0.6483 - val_loss: 0.8419 - val_accuracy: 0.5205\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20dd1665520>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from keras.regularizers import l2\n",
    "\n",
    "LAYERS = [8, 8, 8, 2]                \n",
    "N = 20              \n",
    "LR = 1e-2                   \n",
    "LAMBD = 3e-2                      \n",
    "DP = 0.0                         \n",
    "RDP = 0.0                      \n",
    "T=Lim\n",
    "\n",
    "# Build the Model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(input_shape=(T, N), units=LAYERS[0],\n",
    "               activation='tanh', recurrent_activation='hard_sigmoid',\n",
    "               kernel_regularizer=l2(LAMBD), recurrent_regularizer=l2(LAMBD),\n",
    "               dropout=DP, recurrent_dropout=RDP,\n",
    "               return_sequences=True, return_state=False,\n",
    "               stateful=False, unroll=False\n",
    "              ))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(LSTM(units=LAYERS[1],\n",
    "               activation='tanh', recurrent_activation='hard_sigmoid',\n",
    "               kernel_regularizer=l2(LAMBD), recurrent_regularizer=l2(LAMBD),\n",
    "               dropout=DP, recurrent_dropout=RDP,\n",
    "               return_sequences=True, return_state=False,\n",
    "               stateful=False, unroll=False\n",
    "              ))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(LSTM(units=LAYERS[2],\n",
    "               activation='tanh', recurrent_activation='hard_sigmoid',\n",
    "               kernel_regularizer=l2(LAMBD), recurrent_regularizer=l2(LAMBD),\n",
    "               dropout=DP, recurrent_dropout=RDP,\n",
    "               return_sequences=False, return_state=False,\n",
    "               stateful=False, unroll=False\n",
    "              ))\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(units=LAYERS[3], activation='sigmoid'))\n",
    "\n",
    "# Compile the model with Adam optimizer\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              metrics=['accuracy'],\n",
    "              optimizer='adam')\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(MFCC, Num_labels, test_size=0.05, random_state=np.random.randint(500))\n",
    "\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "                    epochs=150,\n",
    "                    batch_size=126,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4740412",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
