{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89ccca2c",
   "metadata": {},
   "source": [
    "# Neural networks code and tests notebook\n",
    "\n",
    "# This notebook takes the flux and photon index data and try to predict classes from this data on a :\n",
    "\n",
    "# - Conv1D network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "664bcd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import random\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import math\n",
    "from scipy import interpolate\n",
    "import sys \n",
    "from re import search\n",
    "from astropy.io import fits\n",
    "from astropy import units as u\n",
    "from astropy.time import Time\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy.coordinates import ICRS, Galactic, FK4, FK5  # Low-level frames\n",
    "from astropy.coordinates import Angle, Latitude, Longitude\n",
    "import shutil\n",
    "from keras.callbacks import CSVLogger\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import glob\n",
    "from datetime import datetime\n",
    "from keras.layers import Conv1D, Dense, Dropout, Input, Concatenate, GlobalMaxPooling1D, BatchNormalization,GlobalAveragePooling1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import dstack\n",
    "from pandas import read_csv\n",
    "from matplotlib import pyplot\n",
    "import tensorflow.keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten,LSTM\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense, Activation, Concatenate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import ShuffleSplit # or StratifiedShuffleSplit\n",
    "from pandas import DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da642277",
   "metadata": {},
   "outputs": [],
   "source": [
    "pathON=\"C:/Users/pierr/Documents_kanop/Shps/Pierre_points_for_louis/Bureau/interpo_ONOFF_GOLD/ON_data/\"\n",
    "pathOFF=\"C:/Users/pierr/Documents_kanop/Shps/Pierre_points_for_louis/Bureau/interpo_ONOFF_GOLD/OFF_data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7596790",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Storing in a list the adresses of all the data files in the notebook\n",
    "\n",
    "data_files_ON=[]\n",
    "file_names_ON=[]\n",
    "\n",
    "data_files_OFF=[]\n",
    "file_names_OFF=[]\n",
    "data_files_ALL=[]\n",
    "file_names_ALL=[]\n",
    "\n",
    "#Storing in a list the adresses of all the data files in the notebook\n",
    "for filename in os.listdir(pathOFF):\n",
    "    f = os.path.join(pathOFF,filename)\n",
    "    if os.path.isfile(f):\n",
    "        data_files_OFF.append(f)\n",
    "        file_names_OFF.append(filename)\n",
    "        data_files_ALL.append(f)\n",
    "        file_names_ALL.append(filename)\n",
    "for filename in os.listdir(pathON):\n",
    "    f = os.path.join(pathON,filename)\n",
    "    if os.path.isfile(f):\n",
    "        data_files_ON.append(f)\n",
    "        file_names_ON.append(filename)\n",
    "        data_files_ALL.append(f)\n",
    "        file_names_ALL.append(filename)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c01a285",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using data_files with only the 36 binning\n",
    "Filter=True\n",
    "binning=37\n",
    "\n",
    "\n",
    "if Filter==True:\n",
    "    \n",
    "    idx_OFF=[]\n",
    "    idx_ON=[]\n",
    "    dataON=[]\n",
    "    dataOFF=[]\n",
    "    for i in range(len(data_files_OFF)):\n",
    "        dataframe = pd.read_csv(data_files_OFF[i])\n",
    "        lg = len(dataframe)\n",
    "        \n",
    "        if lg==binning:\n",
    "            idx_OFF.append(i)\n",
    "    \n",
    "    for i in range(len(data_files_ON)):\n",
    "        dataframe = pd.read_csv(data_files_ON[i])\n",
    "        lg = len(dataframe)\n",
    "#         print(lg)\n",
    "        if lg==binning:\n",
    "            idx_ON.append(i)\n",
    "\n",
    "    #Future input shape : 3511 sources, 2 features (as time series) , x binnings\n",
    "    for i in range(len(idx_OFF)):\n",
    "\n",
    "        a=idx_OFF[i]\n",
    "        dataOFF.append(data_files_OFF[a])\n",
    "    for i in range(len(idx_ON)):\n",
    "\n",
    "        a=idx_ON[i]\n",
    "        dataON.append(data_files_ON[a])\n",
    "\n",
    "idx = idx_OFF+idx_ON\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fba738f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3D shape of data, multivariate time series\n",
    "\n",
    "lgON=len(dataON)\n",
    "lgOFF=len(dataOFF)\n",
    "lg=lgON+lgOFF\n",
    "Labels = []\n",
    "Class_OFF=[]\n",
    "\n",
    "nbfeatures=3\n",
    "\n",
    "a=binning\n",
    "b=nbfeatures\n",
    "c=lg\n",
    "\n",
    "# multivariate\n",
    "y=np.zeros((2,lg))\n",
    "bigdata= np.zeros((b,c,a))\n",
    "\n",
    "\n",
    "for j in range(len(dataOFF)):\n",
    "\n",
    "    dataframe=pd.read_csv(dataOFF[j],index_col=[0])\n",
    "    dataframe.columns=['MJD','Flux','Delta Flux','Photon Index','Delta Index','TS','fratio']\n",
    "\n",
    "    bigdata[0][j]=dataframe['Flux']\n",
    "    bigdata[1][j]=dataframe['Photon Index']*dataframe['Flux']\n",
    "    bigdata[2][j]=dataframe['Photon Index']\n",
    "\n",
    "for j in range(len(dataON)):\n",
    "\n",
    "    v=j+len(dataOFF)\n",
    "    dataframe=pd.read_csv(dataON[j],index_col=[0])\n",
    "    dataframe.columns=['MJD','Flux','Delta Flux','Photon Index','Delta Index','TS','fratio']\n",
    "\n",
    "    bigdata[0][v]=dataframe['Flux']\n",
    "    bigdata[1][v]=dataframe['Photon Index']*dataframe['Flux']\n",
    "    bigdata[2][v]=dataframe['Photon Index']\n",
    "\n",
    "\n",
    "\n",
    "for i in range(lgOFF):\n",
    "    \n",
    "    Labels.append(int(0))\n",
    "    \n",
    "for i in range(lgON):\n",
    "    \n",
    "    Labels.append(int(1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "649468fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reshaping data matrix\n",
    "bigdata=bigdata.reshape(c,nbfeatures,binning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6c7287c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "980/980 [==============================] - 5s 3ms/step - loss: 0.4805 - binary_accuracy: 0.6699\n",
      "Epoch 2/5\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 0.3919 - binary_accuracy: 0.7020\n",
      "Epoch 3/5\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 0.3832 - binary_accuracy: 0.7010\n",
      "Epoch 4/5\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 0.3949 - binary_accuracy: 0.7092\n",
      "Epoch 5/5\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 0.3686 - binary_accuracy: 0.7010\n",
      "Iteration no. 0\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "Epoch 1/5\n",
      "980/980 [==============================] - 5s 3ms/step - loss: 0.4755 - binary_accuracy: 0.7071\n",
      "Epoch 2/5\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 0.4019 - binary_accuracy: 0.7061\n",
      "Epoch 3/5\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 0.3871 - binary_accuracy: 0.7010\n",
      "Iteration no. 1\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "Epoch 1/5\n",
      "980/980 [==============================] - 4s 3ms/step - loss: 0.4829 - binary_accuracy: 0.6439\n",
      "Epoch 2/5\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 0.3798 - binary_accuracy: 0.6929\n",
      "Epoch 3/5\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 0.3705 - binary_accuracy: 0.6980\n",
      "Epoch 4/5\n",
      "980/980 [==============================] - 2s 3ms/step - loss: 0.3749 - binary_accuracy: 0.7061\n",
      "Epoch 5/5\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 0.3643 - binary_accuracy: 0.7000\n",
      "Iteration no. 2\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "Epoch 1/5\n",
      "980/980 [==============================] - 3s 2ms/step - loss: 0.4783 - binary_accuracy: 0.6893\n",
      "Epoch 2/5\n",
      "980/980 [==============================] - 2s 2ms/step - loss: 0.3892 - binary_accuracy: 0.7163\n",
      "Epoch 3/5\n",
      "980/980 [==============================] - 2s 2ms/step - loss: 0.3837 - binary_accuracy: 0.7010\n",
      "Epoch 4/5\n",
      "980/980 [==============================] - 2s 2ms/step - loss: 0.3804 - binary_accuracy: 0.7061\n",
      "Iteration no. 3\n",
      "4/4 [==============================] - 0s 171us/step\n",
      "Epoch 1/5\n",
      "980/980 [==============================] - 3s 2ms/step - loss: 0.5065 - binary_accuracy: 0.6862\n",
      "Epoch 2/5\n",
      "980/980 [==============================] - 2s 2ms/step - loss: 0.3950 - binary_accuracy: 0.7000\n",
      "Epoch 3/5\n",
      "980/980 [==============================] - 2s 2ms/step - loss: 0.4080 - binary_accuracy: 0.6990\n",
      "Epoch 4/5\n",
      "980/980 [==============================] - 2s 2ms/step - loss: 0.3845 - binary_accuracy: 0.7020\n",
      "Epoch 5/5\n",
      "980/980 [==============================] - 2s 2ms/step - loss: 0.3816 - binary_accuracy: 0.7031\n",
      "Iteration no. 4\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "Epoch 1/5\n",
      "980/980 [==============================] - 3s 2ms/step - loss: 0.4687 - binary_accuracy: 0.6857\n",
      "Epoch 2/5\n",
      "980/980 [==============================] - 2s 2ms/step - loss: 0.3955 - binary_accuracy: 0.6898\n",
      "Epoch 3/5\n",
      "980/980 [==============================] - 2s 2ms/step - loss: 0.3868 - binary_accuracy: 0.6908\n",
      "Epoch 4/5\n",
      "980/980 [==============================] - 2s 2ms/step - loss: 0.3822 - binary_accuracy: 0.6908\n",
      "Epoch 5/5\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 0.3765 - binary_accuracy: 0.6918\n",
      "Iteration no. 5\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "Epoch 1/5\n",
      "980/980 [==============================] - 4s 3ms/step - loss: 0.4730 - binary_accuracy: 0.6923\n",
      "Epoch 2/5\n",
      "980/980 [==============================] - 2s 3ms/step - loss: 0.4061 - binary_accuracy: 0.6969\n",
      "Epoch 3/5\n",
      "980/980 [==============================] - 2s 2ms/step - loss: 0.3924 - binary_accuracy: 0.6939\n",
      "Epoch 4/5\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 0.3873 - binary_accuracy: 0.6939\n",
      "Iteration no. 6\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "Epoch 1/5\n",
      "980/980 [==============================] - 6s 3ms/step - loss: 0.4419 - binary_accuracy: 0.7092\n",
      "Epoch 2/5\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 0.3769 - binary_accuracy: 0.7061\n",
      "Epoch 3/5\n",
      "980/980 [==============================] - 4s 4ms/step - loss: 0.3753 - binary_accuracy: 0.7051\n",
      "Iteration no. 7\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "Epoch 1/5\n",
      "980/980 [==============================] - 5s 3ms/step - loss: 0.4669 - binary_accuracy: 0.7173\n",
      "Epoch 2/5\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 0.3932 - binary_accuracy: 0.6949\n",
      "Epoch 3/5\n",
      "980/980 [==============================] - 2s 2ms/step - loss: 0.3850 - binary_accuracy: 0.6949\n",
      "Iteration no. 8\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "Epoch 1/5\n",
      "980/980 [==============================] - 3s 2ms/step - loss: 0.4693 - binary_accuracy: 0.6903\n",
      "Epoch 2/5\n",
      "980/980 [==============================] - 2s 2ms/step - loss: 0.4063 - binary_accuracy: 0.7082\n",
      "Epoch 3/5\n",
      "980/980 [==============================] - 2s 2ms/step - loss: 0.3863 - binary_accuracy: 0.7092\n",
      "Epoch 4/5\n",
      "980/980 [==============================] - 2s 2ms/step - loss: 0.3817 - binary_accuracy: 0.6969\n",
      "Epoch 5/5\n",
      "980/980 [==============================] - 2s 2ms/step - loss: 0.3803 - binary_accuracy: 0.7051\n",
      "Iteration no. 9\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "Epoch 1/5\n",
      "980/980 [==============================] - 4s 3ms/step - loss: 0.4609 - binary_accuracy: 0.7250\n",
      "Epoch 2/5\n",
      "980/980 [==============================] - 2s 2ms/step - loss: 0.3881 - binary_accuracy: 0.6959\n",
      "Epoch 3/5\n",
      "980/980 [==============================] - 2s 3ms/step - loss: 0.3723 - binary_accuracy: 0.6959\n",
      "Iteration no. 10\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "Epoch 1/5\n",
      "980/980 [==============================] - 4s 2ms/step - loss: 0.5085 - binary_accuracy: 0.6469\n",
      "Epoch 2/5\n",
      "980/980 [==============================] - 2s 2ms/step - loss: 0.4137 - binary_accuracy: 0.6939\n",
      "Epoch 3/5\n",
      "980/980 [==============================] - 2s 2ms/step - loss: 0.4041 - binary_accuracy: 0.6980\n",
      "Epoch 4/5\n",
      "980/980 [==============================] - 2s 2ms/step - loss: 0.3990 - binary_accuracy: 0.6939\n",
      "Epoch 5/5\n",
      "980/980 [==============================] - 2s 2ms/step - loss: 0.3901 - binary_accuracy: 0.6939\n",
      "Iteration no. 11\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "Epoch 1/5\n",
      "980/980 [==============================] - 4s 3ms/step - loss: 0.4827 - binary_accuracy: 0.7143\n",
      "Epoch 2/5\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 0.4024 - binary_accuracy: 0.6959\n",
      "Epoch 3/5\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 0.3975 - binary_accuracy: 0.6959\n",
      "Iteration no. 12\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "Epoch 1/5\n",
      "980/980 [==============================] - 4s 3ms/step - loss: 0.5163 - binary_accuracy: 0.6724\n",
      "Epoch 2/5\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 0.4052 - binary_accuracy: 0.6878\n",
      "Epoch 3/5\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 0.3899 - binary_accuracy: 0.6867\n",
      "Epoch 4/5\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 0.3708 - binary_accuracy: 0.6908\n",
      "Epoch 5/5\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 0.3844 - binary_accuracy: 0.6898\n",
      "Iteration no. 13\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "Epoch 1/5\n",
      "980/980 [==============================] - 8s 4ms/step - loss: 0.4855 - binary_accuracy: 0.6694\n",
      "Epoch 2/5\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 0.4004 - binary_accuracy: 0.6980\n",
      "Epoch 3/5\n",
      "980/980 [==============================] - 4s 4ms/step - loss: 0.3931 - binary_accuracy: 0.7010\n",
      "Epoch 4/5\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 0.3821 - binary_accuracy: 0.7010\n",
      "Epoch 5/5\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 0.3782 - binary_accuracy: 0.7143\n",
      "Iteration no. 14\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "Epoch 1/5\n",
      "980/980 [==============================] - 5s 3ms/step - loss: 0.4705 - binary_accuracy: 0.6898\n",
      "Epoch 2/5\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 0.3936 - binary_accuracy: 0.6949\n",
      "Epoch 3/5\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 0.3825 - binary_accuracy: 0.7031\n",
      "Epoch 4/5\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 0.3904 - binary_accuracy: 0.6969\n",
      "Epoch 5/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "980/980 [==============================] - 3s 3ms/step - loss: 0.3784 - binary_accuracy: 0.7020\n",
      "Iteration no. 15\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "Epoch 1/5\n",
      "980/980 [==============================] - 7s 4ms/step - loss: 0.4835 - binary_accuracy: 0.7592\n",
      "Epoch 2/5\n",
      "980/980 [==============================] - 4s 4ms/step - loss: 0.3995 - binary_accuracy: 0.7082\n",
      "Epoch 3/5\n",
      "980/980 [==============================] - 4s 4ms/step - loss: 0.3749 - binary_accuracy: 0.6969\n",
      "Iteration no. 16\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "Epoch 1/5\n",
      "980/980 [==============================] - 5s 3ms/step - loss: 0.4651 - binary_accuracy: 0.6888\n",
      "Epoch 2/5\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 0.3886 - binary_accuracy: 0.7031\n",
      "Epoch 3/5\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 0.3792 - binary_accuracy: 0.7031\n",
      "Epoch 4/5\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 0.3763 - binary_accuracy: 0.7031\n",
      "Iteration no. 17\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "Epoch 1/5\n",
      "980/980 [==============================] - 4s 3ms/step - loss: 0.5208 - binary_accuracy: 0.6577\n",
      "Epoch 2/5\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 0.3931 - binary_accuracy: 0.6969\n",
      "Epoch 3/5\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 0.3813 - binary_accuracy: 0.7102\n",
      "Epoch 4/5\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 0.3741 - binary_accuracy: 0.6990\n",
      "Epoch 5/5\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 0.3752 - binary_accuracy: 0.6969\n",
      "Iteration no. 18\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "Epoch 1/5\n",
      "980/980 [==============================] - 4s 3ms/step - loss: 0.4647 - binary_accuracy: 0.7571\n",
      "Epoch 2/5\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 0.3879 - binary_accuracy: 0.7071\n",
      "Epoch 3/5\n",
      "980/980 [==============================] - 3s 3ms/step - loss: 0.3925 - binary_accuracy: 0.7041\n",
      "Iteration no. 19\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "Accuracy for ON class:  100.0 %\n",
      "Accuracy for OFF class:  67.73061488283572 %\n",
      "False Positive rate:  0.0 %\n",
      "False Negative rate:  32.26938511716427 %\n",
      "F1 score:  0.7898701966785582\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv1D\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "ON_accuracy=[]\n",
    "OFF_accuracy=[]\n",
    "fscore=[]\n",
    "FPOS=[]\n",
    "FNEG=[]\n",
    "\n",
    "\n",
    "#Measuring the meaned accuracy of  correct prediction of labellisation for each class  over a defined number of steps\n",
    "for i in range(20):\n",
    "    \n",
    "    \n",
    "    nb_filters=20\n",
    "    \n",
    "    weight_for_0 = (1 / lgOFF) * (lg / 2.0)\n",
    "    weight_for_1 = (1 / lgON) * (lg / 2.0)\n",
    "    callback=tensorflow.keras.callbacks.EarlyStopping(monitor='binary_accuracy',patience=2, verbose=0, mode='auto',baseline=None, restore_best_weights=True)\n",
    "    class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "    bigdata=bigdata.reshape(c,binning,nbfeatures)\n",
    "    \n",
    "    #Conv1D Architecture\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(nb_filters, 1, padding=\"same\", activation=\"tanh\",input_shape=(binning,nbfeatures)))\n",
    "    model.add(Conv1D(15, 1, padding=\"same\", activation=\"tanh\",input_shape=(nb_filters,nbfeatures)))\n",
    "    model.add(Conv1D(9, 1, padding=\"same\", activation=\"tanh\",input_shape=(15,nbfeatures)))\n",
    "    model.add(GlobalMaxPooling1D())\n",
    "    model.add(Dense(9, activation='tanh'))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    model.compile(loss=tensorflow.keras.losses.BinaryCrossentropy(reduction='sum'),optimizer='SGD', metrics=['binary_accuracy'])\n",
    "\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(bigdata, Labels, test_size=0.1, random_state=i)\n",
    "    y_test2=y_test.copy()\n",
    "    y_train = to_categorical(y_train)\n",
    "    y_test = to_categorical(y_test)\n",
    "    \n",
    "    #fitting data\n",
    "    model.fit(x_train, y_train,epochs=5,batch_size=1,class_weight=class_weight,callbacks=callback)\n",
    "    \n",
    "    print('Iteration no.',i)\n",
    "    #Obtain the accuracy of prediction for each class\n",
    "    prediction= model.predict(x_test)\n",
    "    predicted_labels=[]\n",
    "    \n",
    "    for i in range(len(prediction)):\n",
    "        if prediction[i][0]>0.5:\n",
    "            predicted_labels.append(0)\n",
    "        else:\n",
    "            predicted_labels.append(1)\n",
    "    on_score=0\n",
    "    on_nbs=0\n",
    "    off_nbs=0\n",
    "    off_score=0\n",
    "    foff=0\n",
    "    fon=0\n",
    "    for i in range(len(y_test)):\n",
    "        if y_test2[i]==1 :\n",
    "            on_nbs+=1\n",
    "            if predicted_labels[i]==1:\n",
    "                on_score+=1\n",
    "            else : \n",
    "                fon+=1\n",
    "        if y_test2[i]==0 :\n",
    "            off_nbs+=1\n",
    "            if predicted_labels[i]==0:\n",
    "                off_score+=1 \n",
    "            else:\n",
    "                foff+=1\n",
    "    if on_nbs>0:    \n",
    "        ON_accuracy.append(100*(on_score/on_nbs))\n",
    "        FPOS.append(100*(fon/on_nbs))\n",
    "    OFF_accuracy.append(100*(off_score/off_nbs))\n",
    "    FNEG.append(100*(foff/off_nbs))\n",
    "    f1= f1_score(y_test2,predicted_labels,average='weighted')\n",
    "    fscore.append(f1)\n",
    "print(\"Accuracy for ON class: \",np.mean(ON_accuracy) ,\"%\")\n",
    "print(\"Accuracy for OFF class: \",np.mean(OFF_accuracy) ,\"%\")\n",
    "print(\"False Positive rate: \",np.mean(FPOS) ,\"%\")\n",
    "print(\"False Negative rate: \",np.mean(FNEG) ,\"%\")\n",
    "print(\"F1 score: \",np.mean(fscore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b19d8e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
