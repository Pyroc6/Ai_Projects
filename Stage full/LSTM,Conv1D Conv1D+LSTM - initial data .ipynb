{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecca3a13",
   "metadata": {},
   "source": [
    "# Neural networks code and tests notebook\n",
    "\n",
    "# This notebook takes the flux, photon index and fratio data and try to predict classes from this data on a :\n",
    "\n",
    "# - LSTM network\n",
    "# - ConvLSTM network\n",
    "# - Conv1D network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95e6f94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import random\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import math\n",
    "from scipy import interpolate\n",
    "import sys \n",
    "from re import search\n",
    "from astropy.io import fits\n",
    "from astropy import units as u\n",
    "from astropy.time import Time\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy.coordinates import ICRS, Galactic, FK4, FK5  # Low-level frames\n",
    "from astropy.coordinates import Angle, Latitude, Longitude\n",
    "import shutil\n",
    "from keras.callbacks import CSVLogger\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import glob\n",
    "from datetime import datetime\n",
    "from keras.layers import Conv1D, Dense, Dropout, Input, Concatenate, GlobalMaxPooling1D, BatchNormalization\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import dstack\n",
    "from pandas import read_csv\n",
    "from matplotlib import pyplot\n",
    "import tensorflow.keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten,LSTM\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense, Activation, Concatenate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import ShuffleSplit # or StratifiedShuffleSplit\n",
    "from pandas import DataFrame\n",
    "from pyts.classification import BOSSVS\n",
    "from pyts.multivariate.classification import MultivariateClassifier\n",
    "import shutil\n",
    "from keras.callbacks import CSVLogger\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import dstack\n",
    "from pandas import read_csv\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import ShuffleSplit # or StratifiedShuffleSplit\n",
    "from pandas import DataFrame\n",
    "import sktime\n",
    "from sktime.classification.distance_based import KNeighborsTimeSeriesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da642277",
   "metadata": {},
   "outputs": [],
   "source": [
    "pathON=\"C:/Users/pierr/Documents_kanop/Shps/Pierre_points_for_louis/Bureau/interpo_ONOFF/Luigino/ON_data/\"\n",
    "pathOFF=\"C:/Users/pierr/Documents_kanop/Shps/Pierre_points_for_louis/Bureau/interpo_ONOFF/Luigino/OFF_data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7596790",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Storing in a list the adresses of all the data files in the notebook\n",
    "\n",
    "data_files_ON=[]\n",
    "file_names_ON=[]\n",
    "\n",
    "data_files_OFF=[]\n",
    "file_names_OFF=[]\n",
    "data_files_ALL=[]\n",
    "file_names_ALL=[]\n",
    "\n",
    "#Storing in a list the adresses of all the data files in the notebook\n",
    "for filename in os.listdir(pathOFF):\n",
    "    f = os.path.join(pathOFF,filename)\n",
    "    if os.path.isfile(f):\n",
    "        data_files_OFF.append(f)\n",
    "        file_names_OFF.append(filename)\n",
    "        data_files_ALL.append(f)\n",
    "        file_names_ALL.append(filename)\n",
    "for filename in os.listdir(pathON):\n",
    "    f = os.path.join(pathON,filename)\n",
    "    if os.path.isfile(f):\n",
    "        data_files_ON.append(f)\n",
    "        file_names_ON.append(filename)\n",
    "        data_files_ALL.append(f)\n",
    "        file_names_ALL.append(filename)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c01a285",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using data_files with only the 36 binning\n",
    "Filter=True\n",
    "binning=37\n",
    "\n",
    "\n",
    "if Filter==True:\n",
    "    \n",
    "    idx_OFF=[]\n",
    "    idx_ON=[]\n",
    "    dataON=[]\n",
    "    dataOFF=[]\n",
    "    for i in range(len(data_files_OFF)):\n",
    "        dataframe = pd.read_csv(data_files_OFF[i])\n",
    "        lg = len(dataframe)\n",
    "        \n",
    "        if lg==binning:\n",
    "            idx_OFF.append(i)\n",
    "    \n",
    "    for i in range(len(data_files_ON)):\n",
    "        dataframe = pd.read_csv(data_files_ON[i])\n",
    "        lg = len(dataframe)\n",
    "        if lg==binning:\n",
    "            idx_ON.append(i)\n",
    "\n",
    "\n",
    "    for i in range(len(idx_OFF)):\n",
    "\n",
    "        a=idx_OFF[i]\n",
    "        dataOFF.append(data_files_OFF[a])\n",
    "    for i in range(len(idx_ON)):\n",
    "\n",
    "        a=idx_ON[i]\n",
    "        dataON.append(data_files_ON[a])\n",
    "\n",
    "idx = idx_OFF+idx_ON\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fba738f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "lgON=len(dataON)\n",
    "lgOFF=len(dataOFF)\n",
    "lg=lgON+lgOFF\n",
    "Labels = []\n",
    "\n",
    "nbfeatures=1\n",
    "\n",
    "a=binning\n",
    "b=nbfeatures\n",
    "c=lg\n",
    "\n",
    "# multivariate\n",
    "\n",
    "data_matrix= np.zeros((b,c,a))\n",
    "\n",
    "#Construct data matrix\n",
    "for j in range(len(dataOFF)):\n",
    "\n",
    "    dataframe=pd.read_csv(dataOFF[j],index_col=[0])\n",
    "    dataframe.columns=['MJD','Flux','Delta Flux','Photon Index','Delta Index','TS','fratio']\n",
    "\n",
    "    data_matrix[0][j]=dataframe['Flux']\n",
    "#     data_matrix[1][j]=dataframe['Photon Index']\n",
    "    \n",
    "for j in range(len(dataON)):\n",
    "\n",
    "    v=j+len(dataOFF)\n",
    "    dataframe=pd.read_csv(dataON[j],index_col=[0])\n",
    "    dataframe.columns=['MJD','Flux','Delta Flux','Photon Index','Delta Index','TS','fratio']\n",
    "\n",
    "    data_matrix[0][v]=dataframe['Flux']\n",
    "#     data_matrix[1][v]=dataframe['Photon Index']\n",
    "    \n",
    "#Creating labels\n",
    "for i in range(lgOFF):\n",
    "    \n",
    "    Labels.append(int(0))\n",
    "    \n",
    "for i in range(lgON):\n",
    "    Labels.append(int(1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "649468fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reshaping data matrix\n",
    "data_matrix=data_matrix.reshape(c,nbfeatures,binning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62b24ef6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "912/912 [==============================] - 4s 2ms/step - loss: 0.6930 - binary_accuracy: 0.7615\n",
      "Epoch 2/20\n",
      "912/912 [==============================] - 2s 2ms/step - loss: 0.6931 - binary_accuracy: 0.4485\n",
      "Epoch 3/20\n",
      "912/912 [==============================] - 2s 2ms/step - loss: 0.6928 - binary_accuracy: 0.2971\n",
      "Epoch 4/20\n",
      "912/912 [==============================] - 2s 2ms/step - loss: 0.6929 - binary_accuracy: 0.6075\n",
      "Epoch 5/20\n",
      "912/912 [==============================] - 2s 2ms/step - loss: 0.6929 - binary_accuracy: 0.7445\n",
      "Epoch 6/20\n",
      "912/912 [==============================] - 2s 2ms/step - loss: 0.6930 - binary_accuracy: 0.6601\n",
      "Epoch 7/20\n",
      "912/912 [==============================] - 2s 2ms/step - loss: 0.6924 - binary_accuracy: 0.6086\n",
      "Iteration no. 0\n",
      "8/8 [==============================] - 1s 2ms/step\n",
      "Epoch 1/20\n",
      "912/912 [==============================] - 3s 2ms/step - loss: 0.7052 - binary_accuracy: 0.3438\n",
      "Epoch 2/20\n",
      "912/912 [==============================] - 2s 2ms/step - loss: 0.7050 - binary_accuracy: 0.2412\n",
      "Epoch 3/20\n",
      "912/912 [==============================] - 2s 2ms/step - loss: 0.7051 - binary_accuracy: 0.4978\n",
      "Epoch 4/20\n",
      "912/912 [==============================] - 2s 2ms/step - loss: 0.7050 - binary_accuracy: 0.1349\n",
      "Epoch 5/20\n",
      "912/912 [==============================] - 2s 2ms/step - loss: 0.7052 - binary_accuracy: 0.3235\n",
      "Epoch 6/20\n",
      "912/912 [==============================] - 2s 2ms/step - loss: 0.7051 - binary_accuracy: 0.3925\n",
      "Epoch 7/20\n",
      "912/912 [==============================] - 2s 2ms/step - loss: 0.7054 - binary_accuracy: 0.1107\n",
      "Epoch 8/20\n",
      "912/912 [==============================] - 2s 2ms/step - loss: 0.7052 - binary_accuracy: 0.1107\n",
      "Epoch 9/20\n",
      "912/912 [==============================] - 2s 2ms/step - loss: 0.7051 - binary_accuracy: 0.2259\n",
      "Iteration no. 1\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Epoch 1/20\n",
      "912/912 [==============================] - 4s 2ms/step - loss: 0.6860 - binary_accuracy: 0.4238\n",
      "Epoch 2/20\n",
      "912/912 [==============================] - 2s 2ms/step - loss: 0.6865 - binary_accuracy: 0.7412\n",
      "Epoch 3/20\n",
      "912/912 [==============================] - 2s 2ms/step - loss: 0.6864 - binary_accuracy: 0.7632\n",
      "Epoch 4/20\n",
      "912/912 [==============================] - 2s 2ms/step - loss: 0.6864 - binary_accuracy: 0.5417\n",
      "Epoch 5/20\n",
      "400/912 [============>.................] - ETA: 0s - loss: 0.6358 - binary_accuracy: 0.9125"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 19>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     29\u001b[0m y_test \u001b[38;5;241m=\u001b[39m to_categorical(y_test)\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m#fitting data\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIteration no.\u001b[39m\u001b[38;5;124m'\u001b[39m,i)\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m#Obtain the accuracy of prediction for each class\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1402\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1403\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1404\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   1405\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[0;32m   1406\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   1407\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m   1408\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1409\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1410\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1411\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2450\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2451\u001b[0m   (graph_function,\n\u001b[0;32m   2452\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2454\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1856\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1857\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1858\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1859\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1860\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1861\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1862\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1863\u001b[0m     args,\n\u001b[0;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1865\u001b[0m     executing_eagerly)\n\u001b[0;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    496\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 497\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    503\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    504\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    505\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    506\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    509\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    510\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#LSTM architecture\n",
    "from keras.layers import Conv1D\n",
    "from sklearn.metrics import f1_score\n",
    "ON_accuracy=[]\n",
    "OFF_accuracy=[]\n",
    "fscore=[]\n",
    "FPOS=[]\n",
    "FNEG= []\n",
    "\n",
    "weight_for_0 = (1 / lgOFF) * (lg / 2.0)\n",
    "weight_for_1 = (1 / lgON) * (lg / 2.0)\n",
    "\n",
    "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "callback=tensorflow.keras.callbacks.EarlyStopping(monitor='binary_accuracy',patience=6, verbose=0, mode='auto',baseline=None, restore_best_weights=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in range(5):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(LSTM(9,input_shape=(nbfeatures,binning),activation='tanh'))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    model.compile(loss=tensorflow.keras.losses.BinaryCrossentropy(reduction='sum'),optimizer='SGD', metrics=['binary_accuracy'])\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(data_matrix, Labels, test_size=0.2, random_state=i)\n",
    "    y_test2=y_test.copy()\n",
    "    y_train = to_categorical(y_train)\n",
    "    y_test = to_categorical(y_test)\n",
    "    \n",
    "    #fitting data\n",
    "    model.fit(x_train, y_train,epochs=20,batch_size=1,class_weight=class_weight,callbacks=callback)\n",
    "\n",
    "    print('Iteration no.',i)\n",
    "    #Obtain the accuracy of prediction for each class\n",
    "    prediction= model.predict(x_test)\n",
    "    predicted_labels=[]\n",
    "    \n",
    "    for i in range(len(prediction)):\n",
    "        if prediction[i][0]>0.5:\n",
    "            predicted_labels.append(0)\n",
    "        else:\n",
    "            predicted_labels.append(1)\n",
    "    on_score=0\n",
    "    on_nbs=0\n",
    "    off_nbs=0\n",
    "    off_score=0\n",
    "    foff=0\n",
    "    fon=0\n",
    "    for i in range(len(y_test)):\n",
    "        if y_test2[i]==1 :\n",
    "            on_nbs+=1\n",
    "            if predicted_labels[i]==1:\n",
    "                on_score+=1\n",
    "            else : \n",
    "                fon+=1\n",
    "        if y_test2[i]==0 :\n",
    "            off_nbs+=1\n",
    "            if predicted_labels[i]==0:\n",
    "                off_score+=1 \n",
    "            else:\n",
    "                foff+=1\n",
    "    if on_nbs>0:    \n",
    "        ON_accuracy.append(100*(on_score/on_nbs))\n",
    "        FPOS.append(100*(fon/on_nbs))\n",
    "    OFF_accuracy.append(100*(off_score/off_nbs))\n",
    "    FNEG.append(100*(foff/off_nbs))\n",
    "    f1= f1_score(y_test2,predicted_labels)\n",
    "    fscore.append(f1)\n",
    "print(\"Accuracy for ON class: \",np.mean(ON_accuracy) ,\"%\")\n",
    "print(\"Accuracy for OFF class: \",np.mean(OFF_accuracy) ,\"%\")\n",
    "print(\"False Positive rate: \",np.mean(FPOS) ,\"%\")\n",
    "print(\"False Negative rate: \",np.mean(FNEG) ,\"%\")\n",
    "print(\"F1 score: \",np.mean(fscore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d2281ed5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "912/912 [==============================] - 4s 2ms/step - loss: 0.6926 - binary_accuracy: 0.3054\n",
      "Epoch 2/10\n",
      "912/912 [==============================] - 2s 2ms/step - loss: 0.6934 - binary_accuracy: 0.8103\n",
      "Epoch 3/10\n",
      "912/912 [==============================] - 2s 2ms/step - loss: 0.6932 - binary_accuracy: 0.6305\n",
      "Epoch 4/10\n",
      "912/912 [==============================] - 2s 2ms/step - loss: 0.6932 - binary_accuracy: 0.4583\n",
      "Epoch 5/10\n",
      "912/912 [==============================] - 2s 2ms/step - loss: 0.6923 - binary_accuracy: 0.6754\n",
      "Epoch 6/10\n",
      "912/912 [==============================] - 2s 2ms/step - loss: 0.6931 - binary_accuracy: 0.3257\n",
      "Epoch 7/10\n",
      "912/912 [==============================] - 2s 2ms/step - loss: 0.6933 - binary_accuracy: 0.3344\n",
      "Epoch 8/10\n",
      "912/912 [==============================] - 2s 2ms/step - loss: 0.6931 - binary_accuracy: 0.7039\n",
      "Iteration no. 0\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Accuracy for ON class:  0.0 %\n",
      "Accuracy for OFF class:  100.0 %\n",
      "False Positive rate:  100.0 %\n",
      "False Negative rate:  0.0 %\n",
      "F1 score:  0.0\n",
      "prec\n"
     ]
    }
   ],
   "source": [
    "# Conv/LSTM architecture\n",
    "#LSTM architecture\n",
    "from keras.layers import Conv1D\n",
    "from sklearn.metrics import f1_score\n",
    "ON_accuracy=[]\n",
    "OFF_accuracy=[]\n",
    "fscore=[]\n",
    "FPOS=[]\n",
    "FNEG= []\n",
    "\n",
    "weight_for_0 = (1 / lgOFF) * (lg / 2.0)\n",
    "weight_for_1 = (1 / lgON) * (lg / 2.0)\n",
    "\n",
    "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "callback=tensorflow.keras.callbacks.EarlyStopping(monitor='binary_accuracy',patience=6, verbose=0, mode='auto',baseline=None, restore_best_weights=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in range(1):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(binning, activation='tanh', input_shape=(nbfeatures,binning),input_dim=nbfeatures))\n",
    "    model.add(Conv1D(filters=20, kernel_size=1, activation='tanh'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(20,input_shape=(20, nbfeatures), activation='tanh'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    model.compile(loss=tensorflow.keras.losses.BinaryCrossentropy(reduction='sum'),optimizer='SGD', metrics=['binary_accuracy'])\n",
    "    x_train, x_test, y_train, y_test = train_test_split(data_matrix, Labels, test_size=0.2, random_state=i)\n",
    "    y_test2=y_test.copy()\n",
    "    y_train = to_categorical(y_train)\n",
    "    y_test = to_categorical(y_test)\n",
    "    \n",
    "    #fitting data\n",
    "    model.fit(x_train, y_train,epochs=10,batch_size=1,class_weight=class_weight,callbacks=callback)\n",
    "\n",
    "    print('Iteration no.',i)\n",
    "    #Obtain the accuracy of prediction for each class\n",
    "    prediction= model.predict(x_test)\n",
    "    predicted_labels=[]\n",
    "    \n",
    "    for i in range(len(prediction)):\n",
    "        if prediction[i][0]>0.5:\n",
    "            predicted_labels.append(0)\n",
    "        else:\n",
    "            predicted_labels.append(1)\n",
    "    on_score=0\n",
    "    on_nbs=0\n",
    "    off_nbs=0\n",
    "    off_score=0\n",
    "    foff=0\n",
    "    fon=0\n",
    "    for i in range(len(y_test)):\n",
    "        if y_test2[i]==1 :\n",
    "            on_nbs+=1\n",
    "            if predicted_labels[i]==1:\n",
    "                on_score+=1\n",
    "            else : \n",
    "                fon+=1\n",
    "        if y_test2[i]==0 :\n",
    "            off_nbs+=1\n",
    "            if predicted_labels[i]==0:\n",
    "                off_score+=1 \n",
    "            else:\n",
    "                foff+=1\n",
    "    if on_nbs>0:    \n",
    "        ON_accuracy.append(100*(on_score/on_nbs))\n",
    "        FPOS.append(100*(fon/on_nbs))\n",
    "    OFF_accuracy.append(100*(off_score/off_nbs))\n",
    "    FNEG.append(100*(foff/off_nbs))\n",
    "    f1= f1_score(y_test2,predicted_labels)\n",
    "    fscore.append(f1)\n",
    "print(\"Accuracy for ON class: \",np.mean(ON_accuracy) ,\"%\")\n",
    "print(\"Accuracy for OFF class: \",np.mean(OFF_accuracy) ,\"%\")\n",
    "print(\"False Positive rate: \",np.mean(FPOS) ,\"%\")\n",
    "print(\"False Negative rate: \",np.mean(FNEG) ,\"%\")\n",
    "print(\"F1 score: \",np.mean(fscore))\n",
    "print('prec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3e3ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "print(precision_score(y_test2, predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ab5bd759",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "798/798 [==============================] - 2s 2ms/step - loss: 0.6823 - binary_accuracy: 0.5470\n",
      "Epoch 2/200\n",
      "798/798 [==============================] - 1s 2ms/step - loss: 0.6822 - binary_accuracy: 0.8972\n",
      "Epoch 3/200\n",
      "798/798 [==============================] - 1s 2ms/step - loss: 0.6824 - binary_accuracy: 0.8972\n",
      "Epoch 4/200\n",
      "798/798 [==============================] - 1s 2ms/step - loss: 0.6812 - binary_accuracy: 0.3095\n",
      "Epoch 5/200\n",
      "798/798 [==============================] - 1s 2ms/step - loss: 0.6825 - binary_accuracy: 0.8972\n",
      "Epoch 6/200\n",
      "798/798 [==============================] - 1s 2ms/step - loss: 0.6822 - binary_accuracy: 0.8747\n",
      "Epoch 7/200\n",
      "798/798 [==============================] - 1s 2ms/step - loss: 0.6823 - binary_accuracy: 0.8972\n",
      "Epoch 8/200\n",
      "798/798 [==============================] - 1s 2ms/step - loss: 0.6822 - binary_accuracy: 0.7356\n",
      "Epoch 9/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6822 - binary_accuracy: 0.7105\n",
      "Epoch 10/200\n",
      "798/798 [==============================] - 1s 2ms/step - loss: 0.6818 - binary_accuracy: 0.4850\n",
      "Epoch 11/200\n",
      "798/798 [==============================] - 1s 2ms/step - loss: 0.6824 - binary_accuracy: 0.8972\n",
      "Epoch 12/200\n",
      "798/798 [==============================] - 1s 2ms/step - loss: 0.6823 - binary_accuracy: 0.8722\n",
      "Epoch 13/200\n",
      "798/798 [==============================] - 1s 2ms/step - loss: 0.6822 - binary_accuracy: 0.8972\n",
      "Epoch 14/200\n",
      "798/798 [==============================] - 1s 2ms/step - loss: 0.6823 - binary_accuracy: 0.7757\n",
      "Epoch 15/200\n",
      "798/798 [==============================] - 1s 2ms/step - loss: 0.6821 - binary_accuracy: 0.8910\n",
      "Epoch 16/200\n",
      "798/798 [==============================] - 1s 2ms/step - loss: 0.6823 - binary_accuracy: 0.8947\n",
      "Epoch 17/200\n",
      "798/798 [==============================] - 1s 2ms/step - loss: 0.6824 - binary_accuracy: 0.7957\n",
      "Epoch 18/200\n",
      "798/798 [==============================] - 1s 2ms/step - loss: 0.6823 - binary_accuracy: 0.8972\n",
      "Epoch 19/200\n",
      "798/798 [==============================] - 1s 2ms/step - loss: 0.6816 - binary_accuracy: 0.5564\n",
      "Epoch 20/200\n",
      "798/798 [==============================] - 1s 2ms/step - loss: 0.6823 - binary_accuracy: 0.8133\n",
      "Epoch 21/200\n",
      "798/798 [==============================] - 1s 2ms/step - loss: 0.6823 - binary_accuracy: 0.8972\n",
      "Epoch 22/200\n",
      "798/798 [==============================] - 1s 2ms/step - loss: 0.6823 - binary_accuracy: 0.8246\n",
      "Epoch 23/200\n",
      "798/798 [==============================] - 1s 2ms/step - loss: 0.6809 - binary_accuracy: 0.3258\n",
      "Epoch 24/200\n",
      "798/798 [==============================] - 1s 2ms/step - loss: 0.6825 - binary_accuracy: 0.8972\n",
      "Epoch 25/200\n",
      "798/798 [==============================] - 1s 2ms/step - loss: 0.6821 - binary_accuracy: 0.8972\n",
      "Epoch 26/200\n",
      "798/798 [==============================] - 1s 2ms/step - loss: 0.6822 - binary_accuracy: 0.7732\n",
      "Epoch 27/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6817 - binary_accuracy: 0.8935\n",
      "Epoch 28/200\n",
      "798/798 [==============================] - 1s 2ms/step - loss: 0.6824 - binary_accuracy: 0.5652\n",
      "Epoch 29/200\n",
      "798/798 [==============================] - 1s 2ms/step - loss: 0.6823 - binary_accuracy: 0.8622\n",
      "Epoch 30/200\n",
      "798/798 [==============================] - 1s 2ms/step - loss: 0.6819 - binary_accuracy: 0.5539\n",
      "Epoch 31/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6823 - binary_accuracy: 0.8972\n",
      "Epoch 32/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6819 - binary_accuracy: 0.6692\n",
      "Epoch 33/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6822 - binary_accuracy: 0.8935\n",
      "Epoch 34/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6823 - binary_accuracy: 0.8647\n",
      "Epoch 35/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6823 - binary_accuracy: 0.8947\n",
      "Epoch 36/200\n",
      "798/798 [==============================] - 1s 2ms/step - loss: 0.6821 - binary_accuracy: 0.8972\n",
      "Epoch 37/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6821 - binary_accuracy: 0.4637\n",
      "Epoch 38/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6823 - binary_accuracy: 0.8108\n",
      "Epoch 39/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6823 - binary_accuracy: 0.8972\n",
      "Epoch 40/200\n",
      "798/798 [==============================] - 1s 2ms/step - loss: 0.6821 - binary_accuracy: 0.6805\n",
      "Epoch 41/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6824 - binary_accuracy: 0.8972\n",
      "Epoch 42/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6822 - binary_accuracy: 0.8208\n",
      "Epoch 43/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6821 - binary_accuracy: 0.6416\n",
      "Epoch 44/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6823 - binary_accuracy: 0.8684\n",
      "Epoch 45/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6816 - binary_accuracy: 0.4674\n",
      "Epoch 46/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6825 - binary_accuracy: 0.8972\n",
      "Epoch 47/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6821 - binary_accuracy: 0.8008\n",
      "Epoch 48/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6823 - binary_accuracy: 0.8835\n",
      "Epoch 49/200\n",
      "798/798 [==============================] - 1s 2ms/step - loss: 0.6819 - binary_accuracy: 0.8722\n",
      "Epoch 50/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6824 - binary_accuracy: 0.7306\n",
      "Epoch 51/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6821 - binary_accuracy: 0.6717\n",
      "Epoch 52/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6823 - binary_accuracy: 0.8409\n",
      "Epoch 53/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6822 - binary_accuracy: 0.8421\n",
      "Epoch 54/200\n",
      "798/798 [==============================] - 1s 2ms/step - loss: 0.6816 - binary_accuracy: 0.5213\n",
      "Epoch 55/200\n",
      "798/798 [==============================] - 1s 2ms/step - loss: 0.6820 - binary_accuracy: 0.8972\n",
      "Epoch 56/200\n",
      "798/798 [==============================] - 2s 2ms/step - loss: 0.6821 - binary_accuracy: 0.5789\n",
      "Epoch 57/200\n",
      "798/798 [==============================] - 1s 2ms/step - loss: 0.6823 - binary_accuracy: 0.7882\n",
      "Epoch 58/200\n",
      "798/798 [==============================] - 1s 2ms/step - loss: 0.6823 - binary_accuracy: 0.8609\n",
      "Epoch 59/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6822 - binary_accuracy: 0.7982\n",
      "Epoch 60/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6823 - binary_accuracy: 0.8897\n",
      "Epoch 61/200\n",
      "798/798 [==============================] - 1s 2ms/step - loss: 0.6823 - binary_accuracy: 0.8584\n",
      "Epoch 62/200\n",
      "798/798 [==============================] - 1s 2ms/step - loss: 0.6824 - binary_accuracy: 0.8947\n",
      "Epoch 63/200\n",
      "798/798 [==============================] - 1s 2ms/step - loss: 0.6824 - binary_accuracy: 0.8935\n",
      "Epoch 64/200\n",
      "798/798 [==============================] - 1s 2ms/step - loss: 0.6819 - binary_accuracy: 0.5476\n",
      "Epoch 65/200\n",
      "798/798 [==============================] - 1s 2ms/step - loss: 0.6824 - binary_accuracy: 0.8972\n",
      "Epoch 66/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6823 - binary_accuracy: 0.8972\n",
      "Epoch 67/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6823 - binary_accuracy: 0.7957\n",
      "Epoch 68/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6822 - binary_accuracy: 0.8759\n",
      "Epoch 69/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6821 - binary_accuracy: 0.8922\n",
      "Epoch 70/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6823 - binary_accuracy: 0.6679\n",
      "Epoch 71/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6824 - binary_accuracy: 0.7306\n",
      "Epoch 72/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6822 - binary_accuracy: 0.7920\n",
      "Epoch 73/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6822 - binary_accuracy: 0.8972\n",
      "Epoch 74/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6823 - binary_accuracy: 0.7945\n",
      "Epoch 75/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6823 - binary_accuracy: 0.8484\n",
      "Epoch 76/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6822 - binary_accuracy: 0.6830\n",
      "Epoch 77/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6823 - binary_accuracy: 0.8058\n",
      "Epoch 78/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6821 - binary_accuracy: 0.6867\n",
      "Epoch 79/200\n",
      "798/798 [==============================] - 1s 2ms/step - loss: 0.6819 - binary_accuracy: 0.8972\n",
      "Epoch 80/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6822 - binary_accuracy: 0.6316\n",
      "Epoch 81/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6823 - binary_accuracy: 0.8835\n",
      "Epoch 82/200\n",
      "798/798 [==============================] - 1s 2ms/step - loss: 0.6823 - binary_accuracy: 0.8847\n",
      "Epoch 83/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6819 - binary_accuracy: 0.5150\n",
      "Epoch 84/200\n",
      "798/798 [==============================] - 1s 2ms/step - loss: 0.6824 - binary_accuracy: 0.8910\n",
      "Epoch 85/200\n",
      "798/798 [==============================] - 1s 2ms/step - loss: 0.6822 - binary_accuracy: 0.8709\n",
      "Epoch 86/200\n",
      "798/798 [==============================] - 1s 2ms/step - loss: 0.6823 - binary_accuracy: 0.8058\n",
      "Epoch 87/200\n",
      "798/798 [==============================] - 1s 2ms/step - loss: 0.6820 - binary_accuracy: 0.6729\n",
      "Epoch 88/200\n",
      "798/798 [==============================] - 1s 2ms/step - loss: 0.6823 - binary_accuracy: 0.8947\n",
      "Epoch 89/200\n",
      "798/798 [==============================] - 1s 2ms/step - loss: 0.6823 - binary_accuracy: 0.8208\n",
      "Epoch 90/200\n",
      "798/798 [==============================] - 1s 2ms/step - loss: 0.6822 - binary_accuracy: 0.7544\n",
      "Epoch 91/200\n",
      "798/798 [==============================] - 1s 2ms/step - loss: 0.6823 - binary_accuracy: 0.8810\n",
      "Epoch 92/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6819 - binary_accuracy: 0.8922\n",
      "Epoch 93/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6821 - binary_accuracy: 0.5301\n",
      "Epoch 94/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6818 - binary_accuracy: 0.8872\n",
      "Epoch 95/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6823 - binary_accuracy: 0.6416\n",
      "Epoch 96/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6823 - binary_accuracy: 0.7406\n",
      "Epoch 97/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6818 - binary_accuracy: 0.8221\n",
      "Epoch 98/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6814 - binary_accuracy: 0.2744\n",
      "Epoch 99/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6820 - binary_accuracy: 0.8935\n",
      "Epoch 100/200\n",
      "798/798 [==============================] - 1s 2ms/step - loss: 0.6821 - binary_accuracy: 0.6341\n",
      "Epoch 101/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6823 - binary_accuracy: 0.8972\n",
      "Epoch 102/200\n",
      "798/798 [==============================] - 1s 2ms/step - loss: 0.6822 - binary_accuracy: 0.7356\n",
      "Epoch 103/200\n",
      "798/798 [==============================] - 1s 2ms/step - loss: 0.6823 - binary_accuracy: 0.8697\n",
      "Epoch 104/200\n",
      "798/798 [==============================] - 2s 2ms/step - loss: 0.6823 - binary_accuracy: 0.8972\n",
      "Epoch 105/200\n",
      "798/798 [==============================] - 1s 2ms/step - loss: 0.6823 - binary_accuracy: 0.8972\n",
      "Epoch 106/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6823 - binary_accuracy: 0.7632\n",
      "Epoch 107/200\n",
      "798/798 [==============================] - 1s 2ms/step - loss: 0.6822 - binary_accuracy: 0.8358\n",
      "Epoch 108/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6819 - binary_accuracy: 0.5614\n",
      "Epoch 109/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6821 - binary_accuracy: 0.6729\n",
      "Epoch 110/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6818 - binary_accuracy: 0.8960\n",
      "Epoch 111/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6823 - binary_accuracy: 0.7419\n",
      "Epoch 112/200\n",
      "798/798 [==============================] - 1s 2ms/step - loss: 0.6823 - binary_accuracy: 0.8910\n",
      "Epoch 113/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6822 - binary_accuracy: 0.7256\n",
      "Epoch 114/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6821 - binary_accuracy: 0.8972\n",
      "Epoch 115/200\n",
      "798/798 [==============================] - 1s 2ms/step - loss: 0.6824 - binary_accuracy: 0.8133\n",
      "Epoch 116/200\n",
      "798/798 [==============================] - 1s 2ms/step - loss: 0.6821 - binary_accuracy: 0.7982\n",
      "Epoch 117/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6824 - binary_accuracy: 0.8158\n",
      "Epoch 118/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6823 - binary_accuracy: 0.8822\n",
      "Epoch 119/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6823 - binary_accuracy: 0.7694\n",
      "Epoch 120/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6823 - binary_accuracy: 0.8170\n",
      "Epoch 121/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6823 - binary_accuracy: 0.8459\n",
      "Epoch 122/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6823 - binary_accuracy: 0.8847\n",
      "Epoch 123/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6822 - binary_accuracy: 0.8972\n",
      "Epoch 124/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6821 - binary_accuracy: 0.8434\n",
      "Epoch 125/200\n",
      "798/798 [==============================] - 1s 2ms/step - loss: 0.6822 - binary_accuracy: 0.7180\n",
      "Epoch 126/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6822 - binary_accuracy: 0.7569\n",
      "Epoch 127/200\n",
      "798/798 [==============================] - 1s 2ms/step - loss: 0.6823 - binary_accuracy: 0.8810\n",
      "Epoch 128/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6822 - binary_accuracy: 0.8772\n",
      "Epoch 129/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6821 - binary_accuracy: 0.6065\n",
      "Epoch 130/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6822 - binary_accuracy: 0.7607\n",
      "Epoch 131/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6822 - binary_accuracy: 0.8972\n",
      "Epoch 132/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6823 - binary_accuracy: 0.8659\n",
      "Epoch 133/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6822 - binary_accuracy: 0.8872\n",
      "Epoch 134/200\n",
      "798/798 [==============================] - 1s 2ms/step - loss: 0.6823 - binary_accuracy: 0.7256\n",
      "Epoch 135/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6818 - binary_accuracy: 0.7995\n",
      "Epoch 136/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6823 - binary_accuracy: 0.8308\n",
      "Epoch 137/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6819 - binary_accuracy: 0.3421\n",
      "Epoch 138/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6821 - binary_accuracy: 0.8972\n",
      "Epoch 139/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6823 - binary_accuracy: 0.8496\n",
      "Epoch 140/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6823 - binary_accuracy: 0.8383\n",
      "Epoch 141/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6823 - binary_accuracy: 0.7982\n",
      "Epoch 142/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6823 - binary_accuracy: 0.8922\n",
      "Epoch 143/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6823 - binary_accuracy: 0.8672\n",
      "Epoch 144/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6823 - binary_accuracy: 0.8972\n",
      "Epoch 145/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6822 - binary_accuracy: 0.8396\n",
      "Epoch 146/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6823 - binary_accuracy: 0.6128\n",
      "Epoch 147/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6823 - binary_accuracy: 0.8747\n",
      "Epoch 148/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6815 - binary_accuracy: 0.4712\n",
      "Epoch 149/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6824 - binary_accuracy: 0.8972\n",
      "Epoch 150/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6820 - binary_accuracy: 0.8972\n",
      "Epoch 151/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6823 - binary_accuracy: 0.7231\n",
      "Epoch 152/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6821 - binary_accuracy: 0.6642\n",
      "Epoch 153/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6813 - binary_accuracy: 0.4211\n",
      "Epoch 154/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6824 - binary_accuracy: 0.8133\n",
      "Epoch 155/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6824 - binary_accuracy: 0.8584\n",
      "Epoch 156/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6823 - binary_accuracy: 0.8596\n",
      "Epoch 157/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6821 - binary_accuracy: 0.8972\n",
      "Epoch 158/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6822 - binary_accuracy: 0.7632\n",
      "Epoch 159/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6823 - binary_accuracy: 0.8208\n",
      "Epoch 160/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6823 - binary_accuracy: 0.8409\n",
      "Epoch 161/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6822 - binary_accuracy: 0.8509\n",
      "Epoch 162/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6824 - binary_accuracy: 0.8972\n",
      "Epoch 163/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6823 - binary_accuracy: 0.8095\n",
      "Epoch 164/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6822 - binary_accuracy: 0.8421\n",
      "Epoch 165/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6820 - binary_accuracy: 0.8960\n",
      "Epoch 166/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6822 - binary_accuracy: 0.5902\n",
      "Epoch 167/200\n",
      "798/798 [==============================] - 1s 2ms/step - loss: 0.6820 - binary_accuracy: 0.6216\n",
      "Epoch 168/200\n",
      "798/798 [==============================] - 1s 2ms/step - loss: 0.6821 - binary_accuracy: 0.8972\n",
      "Epoch 169/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6823 - binary_accuracy: 0.7907\n",
      "Epoch 170/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6821 - binary_accuracy: 0.6654\n",
      "Epoch 171/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6823 - binary_accuracy: 0.8045\n",
      "Epoch 172/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6823 - binary_accuracy: 0.8910\n",
      "Epoch 173/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6818 - binary_accuracy: 0.8446\n",
      "Epoch 174/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6824 - binary_accuracy: 0.8333\n",
      "Epoch 175/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6821 - binary_accuracy: 0.6165\n",
      "Epoch 176/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6820 - binary_accuracy: 0.6429\n",
      "Epoch 177/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6823 - binary_accuracy: 0.8333\n",
      "Epoch 178/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6820 - binary_accuracy: 0.6090\n",
      "Epoch 179/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6823 - binary_accuracy: 0.8647\n",
      "Epoch 180/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6821 - binary_accuracy: 0.8521\n",
      "Epoch 181/200\n",
      "798/798 [==============================] - 1s 2ms/step - loss: 0.6823 - binary_accuracy: 0.8521\n",
      "Epoch 182/200\n",
      "798/798 [==============================] - 1s 2ms/step - loss: 0.6822 - binary_accuracy: 0.7331\n",
      "Epoch 183/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6823 - binary_accuracy: 0.8972\n",
      "Epoch 184/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6823 - binary_accuracy: 0.8972\n",
      "Epoch 185/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6823 - binary_accuracy: 0.7732\n",
      "Epoch 186/200\n",
      "798/798 [==============================] - 1s 2ms/step - loss: 0.6823 - binary_accuracy: 0.8910\n",
      "Epoch 187/200\n",
      "798/798 [==============================] - 1s 2ms/step - loss: 0.6811 - binary_accuracy: 0.3922\n",
      "Epoch 188/200\n",
      "798/798 [==============================] - 1s 2ms/step - loss: 0.6821 - binary_accuracy: 0.8972\n",
      "Epoch 189/200\n",
      "798/798 [==============================] - 1s 2ms/step - loss: 0.6821 - binary_accuracy: 0.7043\n",
      "Epoch 190/200\n",
      "798/798 [==============================] - 1s 2ms/step - loss: 0.6822 - binary_accuracy: 0.7318\n",
      "Epoch 191/200\n",
      "798/798 [==============================] - 1s 2ms/step - loss: 0.6821 - binary_accuracy: 0.8972\n",
      "Epoch 192/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6823 - binary_accuracy: 0.6429\n",
      "Epoch 193/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6819 - binary_accuracy: 0.5238\n",
      "Epoch 194/200\n",
      "798/798 [==============================] - 1s 2ms/step - loss: 0.6823 - binary_accuracy: 0.8233\n",
      "Epoch 195/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6819 - binary_accuracy: 0.6391\n",
      "Epoch 196/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6822 - binary_accuracy: 0.7469\n",
      "Epoch 197/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6820 - binary_accuracy: 0.8972\n",
      "Epoch 198/200\n",
      "798/798 [==============================] - 1s 2ms/step - loss: 0.6821 - binary_accuracy: 0.5902\n",
      "Epoch 199/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6823 - binary_accuracy: 0.7619\n",
      "Epoch 200/200\n",
      "798/798 [==============================] - 1s 1ms/step - loss: 0.6817 - binary_accuracy: 0.6153\n",
      "Iteration no. 0\n",
      "11/11 [==============================] - 0s 1ms/step\n",
      "Accuracy for ON class:  0.0 %\n",
      "Accuracy for OFF class:  100.0 %\n",
      "False Positive rate:  100.0 %\n",
      "False Negative rate:  0.0 %\n",
      "F1 score:  0.8281936725872653\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "ON_accuracy=[]\n",
    "OFF_accuracy=[]\n",
    "fscore=[]\n",
    "FPOS=[]\n",
    "FNEG=[]\n",
    "#Measuring the meaned accuracy of  correct prediction of labellisation for each class  over a defined number of steps\n",
    "for i in range(1):\n",
    "    nb_filters=20\n",
    "    \n",
    "#     callback=tensorflow.keras.callbacks.EarlyStopping(monitor='binary_accuracy',patience=6, verbose=0, mode='auto',baseline=None, restore_best_weights=True)\n",
    "\n",
    "    #Conv1D Architecture\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(nb_filters, 1, padding=\"same\", activation=\"relu\",input_shape=(nbfeatures,binning)))\n",
    "    model.add(Conv1D(15, 1, padding=\"same\", activation=\"relu\",input_shape=(nb_filters,binning)))\n",
    "    model.add(Conv1D(9, 1, padding=\"same\", activation=\"relu\",input_shape=(15,binning)))\n",
    "    model.add(GlobalMaxPooling1D())\n",
    "    model.add(Dense(9, activation='relu'))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    model.compile(loss='binary_crossentropy',optimizer='SGD', metrics=['binary_accuracy'])\n",
    "\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(data_matrix, Labels, test_size=0.3, random_state=i)\n",
    "    y_test2=y_test.copy()\n",
    "    y_train = to_categorical(y_train)\n",
    "    y_test = to_categorical(y_test)\n",
    "    \n",
    "    #fitting data\n",
    "    model.fit(x_train, y_train,epochs=200,batch_size=1,class_weight=class_weight)\n",
    "\n",
    "    print('Iteration no.',i)\n",
    "    #Obtain the accuracy of prediction for each class\n",
    "    prediction= model.predict(x_test)\n",
    "    predicted_labels=[]\n",
    "    \n",
    "    for i in range(len(prediction)):\n",
    "        if prediction[i][0]>0.5:\n",
    "            predicted_labels.append(0)\n",
    "        else:\n",
    "            predicted_labels.append(1)\n",
    "    on_score=0\n",
    "    on_nbs=0\n",
    "    off_nbs=0\n",
    "    off_score=0\n",
    "    foff=0\n",
    "    fon=0\n",
    "    for i in range(len(y_test)):\n",
    "        if y_test2[i]==1 :\n",
    "            on_nbs+=1\n",
    "            if predicted_labels[i]==1:\n",
    "                on_score+=1\n",
    "            else : \n",
    "                fon+=1\n",
    "        if y_test2[i]==0 :\n",
    "            off_nbs+=1\n",
    "            if predicted_labels[i]==0:\n",
    "                off_score+=1 \n",
    "            else:\n",
    "                foff+=1\n",
    "    if on_nbs>0:    \n",
    "        ON_accuracy.append(100*(on_score/on_nbs))\n",
    "        FPOS.append(100*(fon/on_nbs))\n",
    "    OFF_accuracy.append(100*(off_score/off_nbs))\n",
    "    FNEG.append(100*(foff/off_nbs))\n",
    "    f1= f1_score(y_test2,predicted_labels,average='weighted')\n",
    "    fscore.append(f1)\n",
    "print(\"Accuracy for ON class: \",np.mean(ON_accuracy) ,\"%\")\n",
    "print(\"Accuracy for OFF class: \",np.mean(OFF_accuracy) ,\"%\")\n",
    "print(\"False Positive rate: \",np.mean(FPOS) ,\"%\")\n",
    "print(\"False Negative rate: \",np.mean(FNEG) ,\"%\")\n",
    "print(\"F1 score: \",np.mean(fscore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2b33243b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 1ms/step\n",
      "[0.47833544, 0.47833544, 0.47833544, 0.47833544, 0.47833544, 0.47833544, 0.47833544, 0.47833544, 0.47833544, 0.47833544, 0.47833544, 0.47833544, 0.47833544, 0.47833544, 0.47833544, 0.47833544, 0.47833544, 0.47833544, 0.47833544, 0.47833544, 0.47833544, 0.47833544, 0.47833544, 0.47833544, 0.47833544, 0.47833544, 0.47833544, 0.47833544, 0.47833544, 0.47833544, 0.47833544, 0.47833544, 0.47833544, 0.47833544, 0.47833544, 0.47833544, 0.47833544, 0.47833544, 0.47833544, 0.47833544]\n"
     ]
    }
   ],
   "source": [
    "dens = model.predict(x_test)\n",
    "\n",
    "#print(dens)\n",
    "\n",
    "OFFF=[]\n",
    "ONN=[]\n",
    "idx_ON=[]\n",
    "idx_OFF=[]\n",
    "for i in range(len(y_test2)):\n",
    "    \n",
    "    if y_test2[i]==1:\n",
    "        idx_ON.append(i)\n",
    "    if y_test2[i]==0:\n",
    "        idx_OFF.append(i)        \n",
    "\n",
    "         \n",
    "for i in range(len(dens)):\n",
    "        \n",
    "        OFFF.append(dens[i][0])\n",
    "        ONN.append(dens[i][1])\n",
    "        \n",
    "ONN_true=[ONN[j] for j in idx_ON]\n",
    "OFF_true=[ONN[j] for j in idx_OFF]\n",
    "\n",
    "print(ONN_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f50f2fab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1800x1080 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "# Plotting  model score distribution\n",
    "\n",
    "#kwargs = dict(hist_kws={'alpha':.6}, kde_kws={'linewidth':2})\n",
    "\n",
    "colors = ['r','b']\n",
    "labels=['Vrai background','Vrai signal']\n",
    "fig = plt.figure(figsize=(25,15))\n",
    "# ax1 = fig1.add_subplot(121)\n",
    "plt.hist([OFF_true,ONN_true],50,color=colors,label=labels,alpha=0.75)\n",
    "plt.xlabel(\"Probabilité\",fontsize=20)\n",
    "plt.ylabel(\"Nombre de sources\",fontsize=20)\n",
    "plt.title(\"Histogramme des probabilités d'une source d'être classifiée comme classe signal\",fontsize=20)\n",
    "#ax1.hist(OFF_true,20,color=\"r\", label=\"Prob of being ON for all LC\",density=True,alpha=0.75)\n",
    "#ax1.hist(ONN_true,20,color=\"b\", label=\"Prob of being ON for all LC\",density=True,alpha=0.75)\n",
    "\n",
    "#sns.distplot(ONN, color=\"g\", label=\"Prob of beiung ON for all LC\")\n",
    "#sns.distplot(OFF_true, color=\"r\", label=\"Prob of being ON for OFF LC\")\n",
    "\n",
    "plt.xlim(0,1)\n",
    "plt.xticks(fontsize = 15)\n",
    "plt.yticks(fontsize = 15)\n",
    "#sns.distplot(ONN, color=\"dodgerblue\", label=\"Prob ON\")\n",
    "#sns.distplot(OFFF, color=\"orange\", label=\"OFF\")\n",
    "#plt.title(\"Score density\")\n",
    "# plt.yscale('log')\n",
    "#plt.xlim(0,1)\n",
    "#plt.ylim(0.01,800)\n",
    "plt.grid()\n",
    "\n",
    "plt.legend(fontsize=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6846f5c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.49764633,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.49764633,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.49764633,\n",
       " 0.4976463,\n",
       " 0.49764633,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.49764633,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.49764633,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.49764633,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.49764633,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.49764633,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.49764633,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.49764633,\n",
       " 0.4976463,\n",
       " 0.4976463]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OFF_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dc33441b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.49764633,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.4976463,\n",
       " 0.49764633]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ONN_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480b1e95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
