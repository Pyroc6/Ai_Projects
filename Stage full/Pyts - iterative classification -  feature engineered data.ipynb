{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff1139a5",
   "metadata": {},
   "source": [
    "# PYTS/BOSSVS classification algorithm test and measured accuracies\n",
    "# Tested on transformed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "06b1435d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import random\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import sys \n",
    "import shutil\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import dstack\n",
    "from pandas import read_csv\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import ShuffleSplit # or StratifiedShuffleSplit\n",
    "from pandas import DataFrame\n",
    "import sktime\n",
    "from sktime.classification.distance_based import KNeighborsTimeSeriesClassifier\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "527823ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "pathON=\"C:/Users/pierr/Documents_kanop/Shps/Pierre_points_for_louis/Bureau/interpo_ONOFF/ON_data/\"\n",
    "pathOFF=\"C:/Users/pierr/Documents_kanop/Shps/Pierre_points_for_louis/Bureau/interpo_ONOFF/OFF_data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2d6ba841",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Storing in a list the adresses of all the data files in the notebook\n",
    "\n",
    "data_files_ON=[]\n",
    "file_names_ON=[]\n",
    "\n",
    "data_files_OFF=[]\n",
    "file_names_OFF=[]\n",
    "data_files_ALL=[]\n",
    "file_names_ALL=[]\n",
    "\n",
    "#Storing in a list the adresses of all the data files in the notebook\n",
    "for filename in os.listdir(pathOFF):\n",
    "    f = os.path.join(pathOFF,filename)\n",
    "    if os.path.isfile(f):\n",
    "        data_files_OFF.append(f)\n",
    "        file_names_OFF.append(filename)\n",
    "        data_files_ALL.append(f)\n",
    "        file_names_ALL.append(filename)\n",
    "for filename in os.listdir(pathON):\n",
    "    f = os.path.join(pathON,filename)\n",
    "    if os.path.isfile(f):\n",
    "        data_files_ON.append(f)\n",
    "        file_names_ON.append(filename)\n",
    "        data_files_ALL.append(f)\n",
    "        file_names_ALL.append(filename)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8e8e998f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using data_files with only the 36 binning\n",
    "Filter=True\n",
    "binning=37\n",
    "\n",
    "\n",
    "if Filter==True:\n",
    "    \n",
    "    idx_OFF=[]\n",
    "    idx_ON=[]\n",
    "    dataON=[]\n",
    "    dataOFF=[]\n",
    "    for i in range(len(data_files_OFF)):\n",
    "        dataframe = pd.read_csv(data_files_OFF[i])\n",
    "        lg = len(dataframe)\n",
    "        \n",
    "        if lg==binning:\n",
    "            idx_OFF.append(i)\n",
    "    \n",
    "    for i in range(len(data_files_ON)):\n",
    "        dataframe = pd.read_csv(data_files_ON[i])\n",
    "        lg = len(dataframe)\n",
    "\n",
    "        if lg==binning:\n",
    "            idx_ON.append(i)\n",
    "\n",
    "\n",
    "    for i in range(len(idx_OFF)):\n",
    "\n",
    "        a=idx_OFF[i]\n",
    "        dataOFF.append(data_files_OFF[a])\n",
    "    for i in range(len(idx_ON)):\n",
    "\n",
    "        a=idx_ON[i]\n",
    "        dataON.append(data_files_ON[a])\n",
    "\n",
    "idx = idx_OFF+idx_ON\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9392c0f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1140, 37)\n",
      "Accuracy for ON class:  9.777772227772227 %\n",
      "Accuracy for OFF class:  86.8667478916709 %\n",
      "False Positive rate:  90.22222777222777 %\n",
      "False Negative rate:  13.133252108329105 %\n",
      "F1 score:  0.04134564733407441\n"
     ]
    }
   ],
   "source": [
    "from pyts.classification import BOSSVS\n",
    "from pyts.multivariate.classification import MultivariateClassifier\n",
    "\n",
    "iteration=50\n",
    "lgON=len(dataON)\n",
    "lgOFF=len(dataOFF)\n",
    "lg=lgON+lgOFF\n",
    "\n",
    "binning=37\n",
    "\n",
    "Labels = []\n",
    "Q_ON= []\n",
    "\n",
    "nbfeatures=1\n",
    "ON_accuracy=[]\n",
    "OFF_accuracy=[]\n",
    "fscore=[]\n",
    "FPOS=[]\n",
    "FNEG= []\n",
    "a=binning\n",
    "b=nbfeatures\n",
    "c=len(data_files_ALL)\n",
    "\n",
    "# multivariate\n",
    "y=np.zeros((2,lg))\n",
    "bigdata= np.zeros((b,c,a))\n",
    "\n",
    "for j in range(len(data_files_ALL)):\n",
    "   \n",
    "\n",
    "    dataframe=pd.read_csv(data_files_ALL[j],index_col=[0])\n",
    "    dataframe.columns=['MJD','Flux','Delta Flux','Photon Index','Delta Index','TS','fratio']\n",
    "\n",
    "    bigdata[0][j]=dataframe['Flux']\n",
    "#     bigdata[1][j]=dataframe['Photon Index']*dataframe['Flux']\n",
    "#     bigdata[2][j]=dataframe['Photon Index']\n",
    "\n",
    "for i in range(lgOFF):\n",
    "    \n",
    "    Labels.append(int(0))\n",
    "    \n",
    "for i in range(lgON): \n",
    "    \n",
    "    \n",
    "    Labels.append(int(1))\n",
    "    \n",
    "    \n",
    "bigdata=bigdata.reshape(c,binning)    \n",
    "print(bigdata.shape)\n",
    "for i in range(iteration):\n",
    "    \n",
    "    #3D shape of data, multivariate time series\n",
    "\n",
    "    sss = ShuffleSplit(n_splits=1, test_size=0.2,random_state=i)\n",
    "    X=bigdata\n",
    "    y=Labels\n",
    "\n",
    "    sss.get_n_splits(X, y)\n",
    "    train_index, test_index = next(sss.split(X, y)) \n",
    "\n",
    "    x_train, x_test = X[train_index], X[test_index] \n",
    "\n",
    "    y_train=[]\n",
    "    y_test=[]\n",
    "\n",
    "    for i in range(len(train_index)):\n",
    "        a=train_index[i]\n",
    "        y_train.append(y[a])\n",
    "    for i in range(len(test_index)):\n",
    "\n",
    "        a=test_index[i]\n",
    "        y_test.append(y[a])\n",
    "\n",
    "    y_test2=y_test.copy()\n",
    "\n",
    "    clf = BOSSVS(n_bins=5,anova=True,word_size=9,drop_sum=True)\n",
    "    clf.fit(x_train, y_train)\n",
    "    MultivariateClassifier(...)\n",
    "    clf.predict(x_test)\n",
    "\n",
    "    prediction=np.array(clf.predict(x_test))\n",
    "    on_score=0\n",
    "    on_nbs=0\n",
    "    off_nbs=0\n",
    "    off_score=0\n",
    "    foff=0\n",
    "    fon=0\n",
    "    for i in range(len(y_test)):\n",
    "        if y_test2[i]==1 :\n",
    "            on_nbs+=1\n",
    "            if prediction[i]==1:\n",
    "                on_score+=1\n",
    "                a=test_index[i]\n",
    "                Q_ON.append(a)\n",
    "            else : \n",
    "                fon+=1\n",
    "        if y_test2[i]==0 :\n",
    "            off_nbs+=1\n",
    "            if prediction[i]==0:\n",
    "                off_score+=1 \n",
    "            else:\n",
    "                foff+=1\n",
    "                a=test_index[i]\n",
    "                Q_ON.append(a)\n",
    "    if on_nbs>0:    \n",
    "        ON_accuracy.append(100*(on_score/on_nbs))\n",
    "        FPOS.append(100*(fon/on_nbs))\n",
    "    OFF_accuracy.append(100*(off_score/off_nbs))\n",
    "    FNEG.append(100*(foff/off_nbs))\n",
    "    f1= f1_score(y_test2,prediction)\n",
    "    fscore.append(f1)\n",
    "    \n",
    "print(\"Accuracy for ON class: \",np.mean(ON_accuracy) ,\"%\")\n",
    "print(\"Accuracy for OFF class: \",np.mean(OFF_accuracy) ,\"%\")\n",
    "print(\"False Positive rate: \",np.mean(FPOS) ,\"%\")\n",
    "print(\"False Negative rate: \",np.mean(FNEG) ,\"%\")\n",
    "print(\"F1 score: \",np.mean(fscore))\n",
    "\n",
    "\n",
    "\n",
    "gg = np.unique(Q_ON)\n",
    "Q_ON2=[]\n",
    "Q_ON3=[]\n",
    "errOFF=[]\n",
    "\n",
    "\n",
    "\n",
    "if len(gg)>0:\n",
    "    for i in range(len(Q_ON)):\n",
    "        aa=Q_ON[i]\n",
    "        Q_ON2.append(file_names_ALL[aa])\n",
    "    gg = np.unique(Q_ON2)    \n",
    "    for i in range(len(gg)):\n",
    "        bb=gg[i]\n",
    "        count = Q_ON2.count(bb)\n",
    "        if count>int(iteration/7):\n",
    "            Q_ON3.append([bb,count])\n",
    "            errOFF.append(bb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "007d2633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 0.0, 0.11428571428571428, 0.0425531914893617, 0.15789473684210525, 0.08888888888888888, 0.0, 0.0, 0.0, 0.0425531914893617, 0.04651162790697674, 0.0, 0.0, 0.046511627906976744, 0.05405405405405406, 0.06666666666666667, 0.06451612903225808, 0.05263157894736842, 0.06666666666666667, 0.0975609756097561, 0.05128205128205127, 0.058823529411764705, 0.052631578947368425, 0.0, 0.09090909090909091, 0.0, 0.0, 0.041666666666666664, 0.05263157894736841, 0.05555555555555555, 0.0, 0.0, 0.0, 0.07692307692307693, 0.0, 0.0, 0.04081632653061224, 0.04761904761904762, 0.0, 0.0, 0.0975609756097561, 0.05405405405405405, 0.04761904761904762, 0.0, 0.1, 0.0, 0.10526315789473684, 0.05263157894736842, 0.1]\n"
     ]
    }
   ],
   "source": [
    "print(fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8a8771",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Storing in a list the adresses of all the data files in the notebook\n",
    "\n",
    "data_files_ON=[]\n",
    "file_names_ON=[]\n",
    "\n",
    "data_files_OFF=[]\n",
    "file_names_OFF=[]\n",
    "data_files_ALL=[]\n",
    "file_names_ALL=[]\n",
    "\n",
    "#Storing in a list the adresses of all the data files in the notebook\n",
    "for filename in os.listdir(pathOFF):\n",
    "    f = os.path.join(pathOFF,filename)\n",
    "    if os.path.isfile(f) and filename in errOFF :\n",
    "        data_files_OFF.append(f)\n",
    "        file_names_OFF.append(filename)\n",
    "        data_files_ALL.append(f)\n",
    "        file_names_ALL.append(filename)\n",
    "        \n",
    "for filename in os.listdir(pathON):\n",
    "    f = os.path.join(pathON,filename)\n",
    "    if os.path.isfile(f):\n",
    "        data_files_ON.append(f)\n",
    "        file_names_ON.append(filename)\n",
    "        data_files_ALL.append(f)\n",
    "        file_names_ALL.append(filename)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9033fed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using data_files with only the 36 binning\n",
    "Filter=True\n",
    "binning=37\n",
    "\n",
    "\n",
    "if Filter==True:\n",
    "    \n",
    "    idx_OFF=[]\n",
    "    idx_ON=[]\n",
    "    dataON=[]\n",
    "    dataOFF=[]\n",
    "    for i in range(len(data_files_OFF)):\n",
    "        dataframe = pd.read_csv(data_files_OFF[i])\n",
    "        lg = len(dataframe)\n",
    "        \n",
    "        if lg==binning:\n",
    "            idx_OFF.append(i)\n",
    "    \n",
    "    for i in range(len(data_files_ON)):\n",
    "        dataframe = pd.read_csv(data_files_ON[i])\n",
    "        lg = len(dataframe)\n",
    "\n",
    "        if lg==binning:\n",
    "            idx_ON.append(i)\n",
    "\n",
    "\n",
    "    for i in range(len(idx_OFF)):\n",
    "\n",
    "        a=idx_OFF[i]\n",
    "        dataOFF.append(data_files_OFF[a])\n",
    "    for i in range(len(idx_ON)):\n",
    "\n",
    "        a=idx_ON[i]\n",
    "        dataON.append(data_files_ON[a])\n",
    "\n",
    "idx = idx_OFF+idx_ON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2421f965",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pyts.classification import BOSSVS\n",
    "from pyts.multivariate.classification import MultivariateClassifier\n",
    "\n",
    "iteration=200\n",
    "lgON=len(dataON)\n",
    "lgOFF=len(dataOFF)\n",
    "lg=lgON+lgOFF\n",
    "\n",
    "binning=37\n",
    "\n",
    "Labels = []\n",
    "Q_ON= []\n",
    "\n",
    "nbfeatures=3\n",
    "ON_accuracy=[]\n",
    "OFF_accuracy=[]\n",
    "fscore=[]\n",
    "FPOS=[]\n",
    "FNEG=[]\n",
    "a=binning\n",
    "b=nbfeatures\n",
    "c=len(data_files_ALL)\n",
    "\n",
    "# multivariate\n",
    "y=np.zeros((2,lg))\n",
    "bigdata= np.zeros((b,c,a))\n",
    "\n",
    "for j in range(len(data_files_ALL)):\n",
    "\n",
    "    dataframe=pd.read_csv(data_files_ALL[j],index_col=[0])\n",
    "    dataframe.columns=['MJD','Flux','Delta Flux','Photon Index','Delta Index','TS','fratio']\n",
    "\n",
    "    bigdata[0][j]=dataframe['Flux']\n",
    "    bigdata[1][j]=dataframe['Photon Index']*dataframe['Flux']\n",
    "    bigdata[2][j]=dataframe['Photon Index']\n",
    "\n",
    "for i in range(lgOFF):\n",
    "    \n",
    "    Labels.append(int(0))\n",
    "    \n",
    "for i in range(lgON): \n",
    "    \n",
    "    \n",
    "    Labels.append(int(1))\n",
    "    \n",
    "    \n",
    "bigdata=bigdata.reshape(c,nbfeatures,binning)    \n",
    "print(bigdata.shape)\n",
    "for i in range(iteration):\n",
    "    \n",
    "    #3D shape of data, multivariate time series\n",
    "\n",
    "    sss = ShuffleSplit(n_splits=1, test_size=0.2,random_state=i)\n",
    "    X=bigdata\n",
    "    y=Labels\n",
    "\n",
    "    sss.get_n_splits(X, y)\n",
    "    train_index, test_index = next(sss.split(X, y)) \n",
    "\n",
    "    x_train, x_test = X[train_index], X[test_index] \n",
    "\n",
    "    y_train=[]\n",
    "    y_test=[]\n",
    "\n",
    "    for i in range(len(train_index)):\n",
    "        a=train_index[i]\n",
    "        y_train.append(y[a])\n",
    "    for i in range(len(test_index)):\n",
    "\n",
    "        a=test_index[i]\n",
    "        y_test.append(y[a])\n",
    "\n",
    "    y_test2=y_test.copy()\n",
    "\n",
    "    clf = MultivariateClassifier(BOSSVS(n_bins=5,anova=True,word_size=9,drop_sum=True))\n",
    "    clf.fit(x_train, y_train)\n",
    "    MultivariateClassifier(...)\n",
    "    clf.predict(x_test)\n",
    "\n",
    "    prediction=np.array(clf.predict(x_test))\n",
    "    on_score=0\n",
    "    on_nbs=0\n",
    "    off_nbs=0\n",
    "    off_score=0\n",
    "    foff=0\n",
    "    fon=0\n",
    "    for i in range(len(y_test)):\n",
    "        if y_test2[i]==1 :\n",
    "            on_nbs+=1\n",
    "            if prediction[i]==1:\n",
    "                on_score+=1\n",
    "            else : \n",
    "                fon+=1\n",
    "        if y_test2[i]==0 :\n",
    "            off_nbs+=1\n",
    "            if prediction[i]==0:\n",
    "                off_score+=1 \n",
    "            else:\n",
    "                foff+=1\n",
    "                a=test_index[i]\n",
    "                Q_ON.append(a)\n",
    "    if on_nbs>0:    \n",
    "        ON_accuracy.append(100*(on_score/on_nbs))\n",
    "        FPOS.append(100*(fon/on_nbs))\n",
    "    OFF_accuracy.append(100*(off_score/off_nbs))\n",
    "    FNEG.append(100*(foff/off_nbs))\n",
    "    f1= f1_score(y_test2,prediction,average='weighted')\n",
    "    fscore.append(f1)\n",
    "    \n",
    "print(\"Accuracy for ON class: \",np.mean(ON_accuracy) ,\"%\")\n",
    "print(\"Accuracy for OFF class: \",np.mean(OFF_accuracy) ,\"%\")\n",
    "print(\"False Positive rate: \",np.mean(FPOS) ,\"%\")\n",
    "print(\"False Negative rate: \",np.mean(FNEG) ,\"%\")\n",
    "print(\"F1 score: \",np.mean(fscore))\n",
    "\n",
    "\n",
    "\n",
    "gg = np.unique(Q_ON)\n",
    "Q_ON2=[]\n",
    "Q_ON3=[]\n",
    "errOFF=[]\n",
    "print(len(test_index))\n",
    "print(len(np.unique(Q_ON)))\n",
    "\n",
    "if len(gg)>0:\n",
    "    for i in range(len(Q_ON)):\n",
    "        aa=Q_ON[i]\n",
    "        Q_ON2.append(file_names_ALL[aa])\n",
    "    gg = np.unique(Q_ON2)    \n",
    "    for i in range(len(gg)):\n",
    "        bb=gg[i]\n",
    "        count = Q_ON2.count(bb)\n",
    "        if count>int(iteration/8):\n",
    "            Q_ON3.append([bb,count])\n",
    "            errOFF.append(bb)\n",
    "print(Q_ON3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe57d85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b177a67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Storing in a list the adresses of all the data files in the notebook\n",
    "\n",
    "data_files_ON=[]\n",
    "file_names_ON=[]\n",
    "\n",
    "data_files_OFF=[]\n",
    "file_names_OFF=[]\n",
    "data_files_ALL=[]\n",
    "file_names_ALL=[]\n",
    "\n",
    "#Storing in a list the adresses of all the data files in the notebook\n",
    "for filename in os.listdir(pathOFF):\n",
    "    f = os.path.join(pathOFF,filename)\n",
    "    if os.path.isfile(f) and filename in errOFF :\n",
    "        data_files_OFF.append(f)\n",
    "        file_names_OFF.append(filename)\n",
    "        data_files_ALL.append(f)\n",
    "        file_names_ALL.append(filename)\n",
    "        \n",
    "for filename in os.listdir(pathON):\n",
    "    f = os.path.join(pathON,filename)\n",
    "    if os.path.isfile(f):\n",
    "        data_files_ON.append(f)\n",
    "        file_names_ON.append(filename)\n",
    "        data_files_ALL.append(f)\n",
    "        file_names_ALL.append(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "33637ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using data_files with only the 36 binning\n",
    "Filter=True\n",
    "binning=37\n",
    "\n",
    "\n",
    "if Filter==True:\n",
    "    \n",
    "    idx_OFF=[]\n",
    "    idx_ON=[]\n",
    "    dataON=[]\n",
    "    dataOFF=[]\n",
    "    for i in range(len(data_files_OFF)):\n",
    "        dataframe = pd.read_csv(data_files_OFF[i])\n",
    "        lg = len(dataframe)\n",
    "        \n",
    "        if lg==binning:\n",
    "            idx_OFF.append(i)\n",
    "    \n",
    "    for i in range(len(data_files_ON)):\n",
    "        dataframe = pd.read_csv(data_files_ON[i])\n",
    "        lg = len(dataframe)\n",
    "\n",
    "        if lg==binning:\n",
    "            idx_ON.append(i)\n",
    "\n",
    "\n",
    "    for i in range(len(idx_OFF)):\n",
    "\n",
    "        a=idx_OFF[i]\n",
    "        dataOFF.append(data_files_OFF[a])\n",
    "    for i in range(len(idx_ON)):\n",
    "\n",
    "        a=idx_ON[i]\n",
    "        dataON.append(data_files_ON[a])\n",
    "\n",
    "idx = idx_OFF+idx_ON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1c751043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(124, 3, 37)\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [60]\u001b[0m, in \u001b[0;36m<cell line: 51>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    104\u001b[0m     ON_accuracy\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;241m100\u001b[39m\u001b[38;5;241m*\u001b[39m(on_score\u001b[38;5;241m/\u001b[39mon_nbs))\n\u001b[0;32m    105\u001b[0m     FPOS\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;241m100\u001b[39m\u001b[38;5;241m*\u001b[39m(fon\u001b[38;5;241m/\u001b[39mon_nbs))\n\u001b[1;32m--> 106\u001b[0m OFF_accuracy\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;241m100\u001b[39m\u001b[38;5;241m*\u001b[39m(\u001b[43moff_score\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43moff_nbs\u001b[49m))\n\u001b[0;32m    107\u001b[0m FNEG\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;241m100\u001b[39m\u001b[38;5;241m*\u001b[39m(foff\u001b[38;5;241m/\u001b[39moff_nbs))\n\u001b[0;32m    108\u001b[0m f1\u001b[38;5;241m=\u001b[39m f1_score(y_test2,prediction,average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweighted\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "\n",
    "from pyts.classification import BOSSVS\n",
    "from pyts.multivariate.classification import MultivariateClassifier\n",
    "\n",
    "iteration=200\n",
    "lgON=len(dataON)\n",
    "lgOFF=len(dataOFF)\n",
    "lg=lgON+lgOFF\n",
    "\n",
    "binning=37\n",
    "\n",
    "Labels = []\n",
    "Q_ON= []\n",
    "\n",
    "nbfeatures=3\n",
    "ON_accuracy=[]\n",
    "OFF_accuracy=[]\n",
    "fscore= []\n",
    "FPOS=[]\n",
    "FNEG=[]\n",
    "a=binning\n",
    "b=nbfeatures\n",
    "c=len(data_files_ALL)\n",
    "\n",
    "# multivariate\n",
    "y=np.zeros((2,lg))\n",
    "bigdata= np.zeros((b,c,a))\n",
    "\n",
    "for j in range(len(data_files_ALL)):\n",
    "\n",
    "#         a=Q_ON2[j]\n",
    "\n",
    "    dataframe=pd.read_csv(data_files_ALL[j],index_col=[0])\n",
    "    dataframe.columns=['MJD','Flux','Delta Flux','Photon Index','Delta Index','TS','fratio']\n",
    "\n",
    "    bigdata[0][j]=dataframe['Flux']\n",
    "    bigdata[1][j]=dataframe['Photon Index']*dataframe['Flux']\n",
    "    bigdata[2][j]=dataframe['Photon Index']\n",
    "\n",
    "for i in range(lgOFF):\n",
    "    \n",
    "    Labels.append(int(0))\n",
    "    \n",
    "for i in range(lgON): \n",
    "    \n",
    "    \n",
    "    Labels.append(int(1))\n",
    "    \n",
    "    \n",
    "bigdata=bigdata.reshape(c,nbfeatures,binning)    \n",
    "print(bigdata.shape)\n",
    "for i in range(iteration):\n",
    "    #3D shape of data, multivariate time series\n",
    "\n",
    "    sss = ShuffleSplit(n_splits=1, test_size=0.2,random_state=i)\n",
    "    X=bigdata\n",
    "    y=Labels\n",
    "\n",
    "    sss.get_n_splits(X, y)\n",
    "    train_index, test_index = next(sss.split(X, y)) \n",
    "\n",
    "    x_train, x_test = X[train_index], X[test_index] \n",
    "\n",
    "    y_train=[]\n",
    "    y_test=[]\n",
    "\n",
    "    for i in range(len(train_index)):\n",
    "        a=train_index[i]\n",
    "        y_train.append(y[a])\n",
    "    for i in range(len(test_index)):\n",
    "\n",
    "        a=test_index[i]\n",
    "        y_test.append(y[a])\n",
    "\n",
    "    y_test2=y_test.copy()\n",
    "\n",
    "    clf = MultivariateClassifier(BOSSVS(n_bins=5,anova=True,word_size=9,drop_sum=True))\n",
    "    clf.fit(x_train, y_train)\n",
    "    MultivariateClassifier(...)\n",
    "    clf.predict(x_test)\n",
    "\n",
    "    prediction=np.array(clf.predict(x_test))\n",
    "    on_score=0\n",
    "    on_nbs=0\n",
    "    off_nbs=0\n",
    "    off_score=0\n",
    "    foff=0\n",
    "    fon=0\n",
    "    for i in range(len(y_test)):\n",
    "        if y_test2[i]==1 :\n",
    "            on_nbs+=1\n",
    "            if prediction[i]==1:\n",
    "                on_score+=1\n",
    "            else : \n",
    "                fon+=1\n",
    "        if y_test2[i]==0 :\n",
    "            off_nbs+=1\n",
    "            if prediction[i]==0:\n",
    "                off_score+=1 \n",
    "            else:\n",
    "                foff+=1\n",
    "                a=test_index[i]\n",
    "                Q_ON.append(a)\n",
    "    if on_nbs>0:    \n",
    "        ON_accuracy.append(100*(on_score/on_nbs))\n",
    "        FPOS.append(100*(fon/on_nbs))\n",
    "    OFF_accuracy.append(100*(off_score/off_nbs))\n",
    "    FNEG.append(100*(foff/off_nbs))\n",
    "    f1= f1_score(y_test2,prediction,average='weighted')\n",
    "    fscore.append(f1)\n",
    "    \n",
    "print(\"Accuracy for ON class: \",np.mean(ON_accuracy) ,\"%\")\n",
    "print(\"Accuracy for OFF class: \",np.mean(OFF_accuracy) ,\"%\")\n",
    "print(\"False Positive rate: \",np.mean(FPOS) ,\"%\")\n",
    "print(\"False Negative rate: \",np.mean(FNEG) ,\"%\")\n",
    "print(\"F1 score: \",np.mean(fscore))\n",
    "\n",
    "\n",
    "gg = np.unique(Q_ON)\n",
    "Q_ON2=[]\n",
    "Q_ON3=[]\n",
    "errOFF=[]\n",
    "\n",
    "if len(gg)>0:\n",
    "    for i in range(len(Q_ON)):\n",
    "        aa=Q_ON[i]\n",
    "        Q_ON2.append(file_names_ALL[aa])\n",
    "    gg = np.unique(Q_ON2)    \n",
    "    for i in range(len(gg)):\n",
    "        bb=gg[i]\n",
    "        count = Q_ON2.count(bb)\n",
    "        if count>int(iteration/5):\n",
    "            Q_ON3.append([bb,count])\n",
    "            errOFF.append(bb)\n",
    "print(Q_ON3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11d55ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Storing in a list the adresses of all the data files in the notebook\n",
    "\n",
    "data_files_ON=[]\n",
    "file_names_ON=[]\n",
    "\n",
    "data_files_OFF=[]\n",
    "file_names_OFF=[]\n",
    "data_files_ALL=[]\n",
    "file_names_ALL=[]\n",
    "\n",
    "#Storing in a list the adresses of all the data files in the notebook\n",
    "for filename in os.listdir(pathOFF):\n",
    "    f = os.path.join(pathOFF,filename)\n",
    "    if os.path.isfile(f) and filename in errOFF :\n",
    "        data_files_OFF.append(f)\n",
    "        file_names_OFF.append(filename)\n",
    "        data_files_ALL.append(f)\n",
    "        file_names_ALL.append(filename)\n",
    "        \n",
    "for filename in os.listdir(pathON):\n",
    "    f = os.path.join(pathON,filename)\n",
    "    if os.path.isfile(f):\n",
    "        data_files_ON.append(f)\n",
    "        file_names_ON.append(filename)\n",
    "        data_files_ALL.append(f)\n",
    "        file_names_ALL.append(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e182b57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using data_files with only the 36 binning\n",
    "Filter=True\n",
    "binning=37\n",
    "\n",
    "\n",
    "if Filter==True:\n",
    "    \n",
    "    idx_OFF=[]\n",
    "    idx_ON=[]\n",
    "    dataON=[]\n",
    "    dataOFF=[]\n",
    "    \n",
    "    for i in range(len(data_files_OFF)):\n",
    "        dataframe = pd.read_csv(data_files_OFF[i])\n",
    "        lg = len(dataframe)\n",
    "        \n",
    "        if lg==binning:\n",
    "            idx_OFF.append(i)\n",
    "    \n",
    "    for i in range(len(data_files_ON)):\n",
    "        dataframe = pd.read_csv(data_files_ON[i])\n",
    "        lg = len(dataframe)\n",
    "\n",
    "        if lg==binning:\n",
    "            idx_ON.append(i)\n",
    "\n",
    "\n",
    "    for i in range(len(idx_OFF)):\n",
    "\n",
    "        a=idx_OFF[i]\n",
    "        dataOFF.append(data_files_OFF[a])\n",
    "    for i in range(len(idx_ON)):\n",
    "\n",
    "        a=idx_ON[i]\n",
    "        dataON.append(data_files_ON[a])\n",
    "\n",
    "idx = idx_OFF+idx_ON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b39bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pyts.classification import BOSSVS\n",
    "from pyts.multivariate.classification import MultivariateClassifier\n",
    "\n",
    "iteration=200\n",
    "lgON=len(dataON)\n",
    "lgOFF=len(dataOFF)\n",
    "lg=lgON+lgOFF\n",
    "\n",
    "binning=37\n",
    "\n",
    "Labels = []\n",
    "Q_ON= []\n",
    "\n",
    "nbfeatures=3\n",
    "ON_accuracy=[]\n",
    "OFF_accuracy=[]\n",
    "fscore=[]\n",
    "FPOS=[]\n",
    "FNEG=[]\n",
    "a=binning\n",
    "b=nbfeatures\n",
    "c=len(data_files_ALL)\n",
    "\n",
    "# multivariate\n",
    "y=np.zeros((2,lg))\n",
    "bigdata= np.zeros((b,c,a))\n",
    "\n",
    "for j in range(len(data_files_ALL)):\n",
    "\n",
    "\n",
    "    dataframe=pd.read_csv(data_files_ALL[j])\n",
    "    dataframe.columns=['Iteration2','Iteration','MJD','Flux','Delta Flux','Photon Index','Delta Index','TS','fratio']\n",
    "\n",
    "    bigdata[0][j]=dataframe['Flux']\n",
    "    bigdata[1][j]=dataframe['Photon Index']*dataframe['Flux']\n",
    "    bigdata[2][j]=dataframe['Photon Index']\n",
    "\n",
    "for i in range(lgOFF):\n",
    "    \n",
    "    Labels.append(int(0))\n",
    "    \n",
    "for i in range(lgON): \n",
    "    \n",
    "    \n",
    "    Labels.append(int(1))\n",
    "    \n",
    "    \n",
    "bigdata=bigdata.reshape(c,nbfeatures,binning)    \n",
    "print(bigdata.shape)\n",
    "for i in range(iteration):\n",
    "    #3D shape of data, multivariate time series\n",
    "\n",
    "    sss = ShuffleSplit(n_splits=1, test_size=0.2,random_state=i)\n",
    "    X=bigdata\n",
    "    y=Labels\n",
    "\n",
    "    sss.get_n_splits(X, y)\n",
    "    train_index, test_index = next(sss.split(X, y)) \n",
    "\n",
    "    x_train, x_test = X[train_index], X[test_index] \n",
    "\n",
    "    y_train=[]\n",
    "    y_test=[]\n",
    "\n",
    "    for i in range(len(train_index)):\n",
    "        a=train_index[i]\n",
    "        y_train.append(y[a])\n",
    "    for i in range(len(test_index)):\n",
    "\n",
    "        a=test_index[i]\n",
    "        y_test.append(y[a])\n",
    "\n",
    "    y_test2=y_test.copy()\n",
    "\n",
    "    clf = MultivariateClassifier(BOSSVS(n_bins=5,anova=True,word_size=9,drop_sum=True))\n",
    "    clf.fit(x_train, y_train)\n",
    "    MultivariateClassifier(...)\n",
    "    clf.predict(x_test)\n",
    "\n",
    "    prediction=np.array(clf.predict(x_test))\n",
    "    on_score=0\n",
    "    on_nbs=0\n",
    "    off_nbs=0\n",
    "    off_score=0\n",
    "    foff=0\n",
    "    fon=0\n",
    "    for i in range(len(y_test)):\n",
    "        if y_test2[i]==1 :\n",
    "            on_nbs+=1\n",
    "            if prediction[i]==1:\n",
    "                on_score+=1\n",
    "            else : \n",
    "                fon+=1\n",
    "        if y_test2[i]==0 :\n",
    "            off_nbs+=1\n",
    "            if prediction[i]==0:\n",
    "                off_score+=1 \n",
    "            else:\n",
    "                foff+=1\n",
    "    if on_nbs>0:    \n",
    "        ON_accuracy.append(100*(on_score/on_nbs))\n",
    "        FPOS.append(100*(fon/on_nbs))\n",
    "    OFF_accuracy.append(100*(off_score/off_nbs))\n",
    "    FNEG.append(100*(foff/off_nbs))\n",
    "    f1= f1_score(y_test2,prediction,average='weighted')\n",
    "    fscore.append(f1)\n",
    "    \n",
    "print(\"Accuracy for ON class: \",np.mean(ON_accuracy) ,\"%\")\n",
    "print(\"Accuracy for OFF class: \",np.mean(OFF_accuracy) ,\"%\")\n",
    "print(\"False Positive rate: \",np.mean(FPOS) ,\"%\")\n",
    "print(\"False Negative rate: \",np.mean(FNEG) ,\"%\")\n",
    "print(\"F1 score: \",np.mean(fscore))\n",
    "\n",
    "\n",
    "\n",
    "gg = np.unique(Q_ON)\n",
    "Q_ON2=[]\n",
    "Q_ON3=[]\n",
    "errOFF=[]\n",
    "\n",
    "if len(gg)>0:\n",
    "    for i in range(len(Q_ON)):\n",
    "        aa=Q_ON[i]\n",
    "        Q_ON2.append(file_names_ALL[aa])\n",
    "    gg = np.unique(Q_ON2)    \n",
    "    for i in range(len(gg)):\n",
    "        bb=gg[i]\n",
    "        count = Q_ON2.count(bb)\n",
    "        if count>1:\n",
    "            Q_ON3.append([bb,count])\n",
    "            errOFF.append(bb)\n",
    "print(Q_ON3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781b617f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
