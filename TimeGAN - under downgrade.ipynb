{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26181376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8.13\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e10ae78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ydata_synthetic\n",
    "import pandas as pd\n",
    "from ydata_synthetic.synthesizers import ModelParameters\n",
    "from ydata_synthetic.synthesizers.timeseries import TimeGAN\n",
    "\n",
    "import os \n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8dd6e452",
   "metadata": {},
   "outputs": [],
   "source": [
    "pathON=\"C:/Users/pierr/Documents_kanop/Shps/Pierre_points_for_louis/Bureau/interpo_ONOFF/ON_data/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "120de3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Storing in a list the adresses of all the data files in the notebook\n",
    "\n",
    "data_files_ON=[]\n",
    "file_names_ON=[]\n",
    "\n",
    "data_files_ALL=[]\n",
    "data_files_OFF=[]\n",
    "file_names_OFF=[]\n",
    "file_names_ALL=[]\n",
    "data_files_OFF=[]\n",
    "#Storing in a list the adresses of all the data files in the notebook\n",
    "\n",
    "for filename in os.listdir(pathON):\n",
    "    f = os.path.join(pathON,filename)\n",
    "    if os.path.isfile(f):\n",
    "        data_files_ON.append(f)\n",
    "        file_names_ON.append(filename)\n",
    "        data_files_ALL.append(f)\n",
    "        file_names_ALL.append(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30da5e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using data_files with only the 36 binning\n",
    "Filter=True\n",
    "binning=37\n",
    "nbfeatures=1\n",
    "\n",
    "\n",
    "\n",
    "if Filter==True:\n",
    "    \n",
    "    idx_OFF=[]\n",
    "    idx_ON=[]\n",
    "    dataON=[]\n",
    "    dataOFF=[]\n",
    "    for i in range(len(data_files_OFF)):\n",
    "        dataframe = pd.read_csv(data_files_OFF[i])\n",
    "        lg = len(dataframe)\n",
    "        \n",
    "        if lg==binning:\n",
    "            idx_OFF.append(i)\n",
    "    \n",
    "    for i in range(len(data_files_ON)):\n",
    "        dataframe = pd.read_csv(data_files_ON[i])\n",
    "        lg = len(dataframe)\n",
    "#         print(lg)\n",
    "        if lg==binning:\n",
    "            idx_ON.append(i)\n",
    "\n",
    "    #Construct csv dataframe with features of LC and LC dir\n",
    "    # RA, DEC ,class, file name \n",
    "\n",
    "    #Future input shape : 3511 sources, 2 features (as time series) , x binnings\n",
    "    for i in range(len(idx_OFF)):\n",
    "\n",
    "        a=idx_OFF[i]\n",
    "        dataOFF.append(data_files_OFF[a])\n",
    "    for i in range(len(idx_ON)):\n",
    "\n",
    "        a=idx_ON[i]\n",
    "        dataON.append(data_files_ON[a])\n",
    "\n",
    "idx = idx_OFF+idx_ON\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7b6be49",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "seq_len = 37      # Timesteps\n",
    "n_seq = 1         # Features\n",
    "hidden_dim = 37    # Hidden units for generator (GRU & LSTM).                 # Also decides output_units for generator\n",
    "gamma = 1           # Used for discriminator loss\n",
    "noise_dim = 36 #37 ?      # Used by generator as a starter dimension\n",
    "dim = 128   \n",
    "batch_size = 11\n",
    "learning_rate = 3e-2\n",
    "gan_args = ModelParameters(batch_size=batch_size,\n",
    "                           lr=learning_rate,\n",
    "                           noise_dim=noise_dim,\n",
    "                           layers_dim=dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652f1d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Emddeding network training: 100%|██████████| 300/300 [00:16<00:00, 17.89it/s]\n",
      "Supervised network training: 100%|██████████| 300/300 [00:12<00:00, 23.43it/s]\n",
      "Joint networks training:  99%|█████████▊| 296/300 [06:05<00:04,  1.01s/it]"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "lgON=len(dataON)\n",
    "a=binning\n",
    "b=nbfeatures\n",
    "# c=lgON\n",
    "c=lgON\n",
    "# multivariate\n",
    "y=np.zeros((2,lg))\n",
    "bigdata= np.zeros((c,a,b))\n",
    "\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "for j in range(len(dataON)):\n",
    "    dataframe=pd.read_csv(dataON[j])\n",
    "    dataframe.columns=['Iteration','MJD','Flux','Delta Flux','Photon Index','Delta Index','TS','fratio']\n",
    "    Flux = dataframe['Flux'].values.reshape(-1, 1)\n",
    "#     Photon_idx = dataframe['Photon Index']\n",
    "    Flux= min_max_scaler.fit_transform(Flux)    \n",
    "    bigdata[j]=Flux\n",
    "#         bigdata[j][kk][1]=Photon_idx[kk]\n",
    "\n",
    "        \n",
    "# bigdata=bigdata.reshape(c,binning,nbfeatures)    \n",
    "\n",
    "synth = TimeGAN(model_parameters=gan_args, hidden_dim=hidden_dim, seq_len=binning, n_seq=1, gamma=1)\n",
    "synth.train(bigdata, train_steps=300)\n",
    "    \n",
    "\n",
    "# synth_data = synth.sample(binning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16809ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Flux.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6e733b",
   "metadata": {},
   "outputs": [],
   "source": [
    "synth_data = synth.sample(3)\n",
    "\n",
    "print(synth_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2077a94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pathON=\"C:/Users/pierr/Documents_kanop/Shps/Pierre_points_for_louis/Bureau/interpo_ONOFF/ON_synthetic/\"\n",
    "\n",
    "# for i in range(306):\n",
    "    \n",
    "#     a = synth_data[i]\n",
    "#     df = pd.DataFrame(a)\n",
    "#     new_file_path = pathON+'ON_synthetic_'+str(i)+'.csv'\n",
    "#     df.to_csv(new_file_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055da8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(dataframe[\"MJD\"],synth_data[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28549d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(dataframe[\"MJD\"],Flux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2065f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(exa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52aaa71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
